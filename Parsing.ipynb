{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Parsing.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "x7U-o_zZnpyW"
      ],
      "toc_visible": true,
      "mount_file_id": "1yDq15WALp4ykeprVTZwbR4JRVln3b-DI",
      "authorship_tag": "ABX9TyN5tDtK4Cl7+BVbFdOIJs6l"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Library"
      ],
      "metadata": {
        "id": "sdoQnofjCr8Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rTZ3v9rdTwkG"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.error import HTTPError\n",
        "\n",
        "import http.client as httplib  # or http.client if you're on Python 3 # httplib\n",
        "httplib._MAXHEADERS = 10000\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "import re\n",
        "import gc\n",
        "\n",
        "import json\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "rus_mon_dict = {'янв': '01', 'фев': '02', 'мар': '03',\n",
        "                'апр': '04', 'мая': '05', 'июн': '06',\n",
        "                'июл': '07', 'авг': '08', 'сен': '09',\n",
        "                'окт': '10', 'ноя': '11', 'дек': '12'}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Folders & Files"
      ],
      "metadata": {
        "id": "rlFIffaTPOGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pathes\n",
        "art_project_path = '/content/drive/MyDrive/Art/Art_Project'\n",
        "art_project_path_backups = '/content/drive/MyDrive/Art/Art_Project/parsing_backups'\n",
        "art_project_path_tests = '/content/drive/MyDrive/Art/Art_Project/parsing_tests'\n",
        "\n",
        "# files\n",
        "page_s = '/page_parsing_status.csv'\n",
        "\n",
        "artinvest_s = '/artinvest_pages_counter_stat.csv'\n",
        "artinvest_d = '/artinvest_news_articles_data.csv'\n",
        "artinvest_lt = '/artinvest_long_text.csv'\n",
        "\n",
        "theartnewspaper_d = '/theartnewspaper_data_new.csv'\n",
        "theartnewspaper_lt = '/theartnewspaper_long_text.csv'\n",
        "\n",
        "artchive_s = '/artchive_pages_counter_stat.csv'\n",
        "artchive_d = '/artchive_news_articles_data.csv'\n",
        "artchive_lt = '/artchive_long_text.csv'\n",
        "\n",
        "artuzel_s = '/artusel_pages_counter_stat.csv'\n",
        "artuzel_d = '/artuzel_news_articles_data.csv'\n",
        "artuzel_lt = '/artuzel_long_text.csv'"
      ],
      "metadata": {
        "id": "Ftk2MIOTPNKv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sites' list for parsing"
      ],
      "metadata": {
        "id": "95MQouizMsq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "urls_news = ['https://www.theartnewspaper.ru/', 'https://artinvestment.ru/', 'http://artuzel.com/', 'https://artchive.ru/'] # 'https://artguide.com/', 'http://artuzel.com/', \n",
        "# https://artguide.com/ - <div class=\"chromeframe\">\n",
        "#    Ваш браузер <em>устарел!</em> <a href=\"http://browsehappy.com/\">Установите другой браузер</a> или\n",
        "#    <a href=\"http://www.google.com/chromeframe/?redirect=true\">Google Chrome Frame</a>, чтобы просматривать этот сайт.\n",
        "urls_datasets = ['https://artchive.ru/', 'https://artinvestment.ru/', 'http://artuzel.com/']\n",
        "urls_archives = ['https://artchive.ru/', 'https://russianartarchive.net/ru'] # есть API - https://api.raan.garagemca.org/documentation/#/\n",
        "urls_fairs = ['https://www.cosmoscow.com/ru/']"
      ],
      "metadata": {
        "id": "4HJVOzZl7vuj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# topping up dict (manually yet)\n",
        "#                             site,       s_file,        d_file,        lt_file\n",
        "df_dict = {'https://www.theartnewspaper.ru/': ['-', theartnewspaper_d, theartnewspaper_lt], \n",
        "           'https://artinvestment.ru/': [artinvest_s, artinvest_d, artinvest_lt],\n",
        "           'https://artchive.ru/': [artchive_s, artchive_d, artchive_lt],\n",
        "           'https://artuzel.com/': [artuzel_s, artuzel_d, artuzel_lt]\n",
        "           }"
      ],
      "metadata": {
        "id": "j5VtxoBePgcP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unused code"
      ],
      "metadata": {
        "id": "x7U-o_zZnpyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from requests.exceptions import MissingSchema"
      ],
      "metadata": {
        "id": "YQ8CXMiuFJPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop part of df\n",
        "#artinvest_news_articles_data = artinvest_news_articles_data.drop(artinvest_news_articles_data[artinvest_news_articles_data['page_url']=='20220209_Hirst.html'].index)"
      ],
      "metadata": {
        "id": "ArnJtU3EXaoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# delete all data from df\n",
        "#artinvest_news_articles_data = artinvest_news_articles_data[0:0]\n",
        "#theartnewspaper_data = theartnewspaper_data[0:0]"
      ],
      "metadata": {
        "id": "dMAS2hzMrSie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "#warnings.simplefilter(action='ignore', category=SettingWithCopyWarning)"
      ],
      "metadata": {
        "id": "oFCMPP7zrUdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "HOmGyFTFNKek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Openings and savings\n",
        "1. __open_parsing_dict()__ -> parsing_dict - Open dict with sites for parsing\n",
        "2. __open_file_csv(file, folder)__ -> df - Open file.csv\n",
        "3. __save_df_file(df, file, folder)__ -> - Save df to csv file\n",
        "4. __open_long_text_url_list_temp()__ -> parsing_list - Open json artinvest_long_text_url_list_temp\n",
        "5. __save_long_text_url_list_temp(parsing_list)__ -> - Save json artinvest_long_text_url_list_temp"
      ],
      "metadata": {
        "id": "1Py5yix5qYh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Open dict with sites for parsing\n",
        "def open_parsing_dict():\n",
        "  with open(art_project_path + '/sites_for_parsing.txt', 'rb') as infile:\n",
        "    parsing_dict = json.load(infile)\n",
        "  return parsing_dict\n",
        "\n",
        "# 2. Open file.csv\n",
        "def open_file_csv(file, folder): # folder: live, backup or test\n",
        "  if folder=='live':\n",
        "    df = pd.read_csv(art_project_path + file)\n",
        "  elif folder=='backup':\n",
        "    df = pd.read_csv(art_project_path_backups + file)\n",
        "  elif folder=='test':\n",
        "    df = pd.read_csv(art_project_path_tests + file)\n",
        "  return df\n",
        "\n",
        "# 3. Save df to csv file\n",
        "def save_df_file(df, file, folder): # folder: live, backup or test\n",
        "  if folder=='live':\n",
        "    df.to_csv(art_project_path + file, index=False)\n",
        "  elif folder=='backup':\n",
        "    df.to_csv(art_project_path_backups + file, index=False)\n",
        "  elif folder=='test':\n",
        "    df.to_csv(art_project_path_tests + file, index=False)\n",
        "\n",
        "# 4. Open json long_text_url_list_temp\n",
        "def open_long_text_url_list_temp():\n",
        "  with open(art_project_path + '/long_text_url_list_temp.txt', 'rb') as infile:\n",
        "    parsing_list = json.load(infile)\n",
        "  return parsing_list\n",
        "\n",
        "# 5. Save json long_text_url_list_temp\n",
        "def save_long_text_url_list_temp(parsing_list):\n",
        "  with open(art_project_path + '/long_text_url_list_temp.txt', 'w') as outfile:\n",
        "    json.dump(parsing_list, outfile)"
      ],
      "metadata": {
        "id": "g2vgnc4LOU-X"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data mining\n",
        "6. __get_page(url)__ -> bs_page - Collect request status\n",
        "7. __get_parsing_lists(site)__ -> links, titles - Get links & titles lists\n",
        "8. Parsing pages_counter_stat:\n",
        "- 8.1 __get_artinvest_pages_counter_stat(page_url, page, parsing_links, parsing_titles)__ -> df_counter_new - Parsing artinvestment pages_counter_stat\n",
        "- 8.2 __get_artch_pages_counter_stat(page_url, page, parsing_links, parsing_titles)__ -> df_counter_new - Parsing artchive pages_counter_stat\n",
        "- 8.3 __get_artuz_pages_counter_stat(page_url, page, parsing_links, parsing_titles)__ -> df_counter_new - Parsing artuzel pages_counter_stat\n",
        "9. Parsing current news_articles_data:\n",
        "- 9.1 __get_artinvest_pages_curr_data(page_url, page, parsing_links, parsing_titles)__ -> df_data_new, long_text_url_list_new, print(message) - Parsing artinvestment current news_articles_data\n",
        "- 9.2 __get_tanp_pages_curr_data(page_url, page, parsing_links, parsing_titles)__ -> df_data_new, long_text_url_list_new, print(message) - Parsing theartnewspaper current news_articles_data\n",
        "- 9.3 __get_artch_pages_curr_data(page_url, page, parsing_links, parsing_titles)__ -> df_data_new, long_text_url_list_new, print(message) - Parsing artchive current news_articles_data\n",
        "- 9.4 __get_artuz_pages_curr_data(page_url, page, parsing_links, parsing_titles)__ -> df_data_new, long_text_url_list_new, print(message) - Parsing artuzel current news_articles_data\n",
        "10. Parsing long texts:\n",
        "- 10.1 __get_artinvest_long_text(text_page)__ -> long_text_list_new, sourses_list_new, parsing_speed_list_new - Parsing artinvestment long texts\n",
        "- 10.2 __get_tanp_long_text(text_page)__ -> long_text_list_new, sourses_list_new, parsing_speed_list_new - Parsing theartnewspaper long texts\n",
        "- 10.3 __get_artch_long_text(text_page)__ -> long_text_list_new, sourses_list_new, parsing_speed_list_new - Parsing artchive long texts\n",
        "- 10.4 __get_artuz_long_text(text_page)__ -> long_text_list_new, sourses_list_new, parsing_speed_list_new - Parsing artuzel long texts\n",
        "11. Functions aggrigators:\n",
        "- 11.1 __parsing_agg_sd(site, s_file, d_file, lt_file)__ -> print(message) - Getting pages_counter_stat, pages_curr_data csv files and json long_text_url_list_temp\n",
        "- 11.2 __parsing_agg_lt(lt_file)__ -> print(message) - Getting long texts files\n",
        "- 11.3 __parsing_agg_a_n_archive(s_file, d_file, lt_file, p_url)__ Parsing news_articles_data ARCHIVE\n",
        "12. __long_text_problems_fix(lt_file, df)__ -> print(message) - Fixing long text problems\n",
        "13. Parsing news_articles_data ARCHIVE\n",
        "- 13.1 __get_artinvest_next_page_url_list(first_page_url, pages_total)__ -> next_page_url_list_new - Parsing artinvestment news_articles_data ARCHIVE\n",
        "- 13.2 __get_artch_next_page_url_list(first_page_url, pages_total)__ -> next_page_url_list_new - Parsing artchive news_articles_data ARCHIVE\n",
        "- 13.3 __get_artuz_next_page_url_list(first_page_url, pages_total)__ -> next_page_url_list_new - Parsing artuzel news_articles_data ARCHIVE\n",
        "14. __date_transfomation(cell)__ -> cell - Date transfomation\n",
        "15. __collect_lines_check(pages_counter_stat, news_articles_data)__ -> problem_archive_pages - Checking collected lines"
      ],
      "metadata": {
        "id": "ySkBh6S8q6wv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### get_page"
      ],
      "metadata": {
        "id": "suaU4o20Yxvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Collect request status - saving every get result\n",
        "\n",
        "def get_page(url):\n",
        "  start_time = time.time()\n",
        "\n",
        "  response = requests.get(url, headers={'User-Agent': 'Chrome/97.0.4692.71'}) # timeout=0.001\n",
        "# Edge/97.0.1072.55\n",
        "# Chrome/97.0.4692.71\n",
        "  try:\n",
        "    response.raise_for_status()\n",
        "\n",
        "  except requests.exceptions.HTTPError: # for correction\n",
        "    sys.exit(print('HTTPError: ' + str(url)))\n",
        "\n",
        "#except (HTTPError, MissingSchema): \n",
        "# 503 Server Error: Service Temporarily Unavailable for url: https://artinvestment.ru/news/artnews/ \n",
        "# Invalid URL\n",
        "\n",
        "  else:\n",
        "    get_page_stat_new = pd.DataFrame({'page_url': [url],\n",
        "                                      'status_code': [response.status_code],\n",
        "                                      'encoding': [response.encoding],\n",
        "                                      'raise_for_status': [response.raise_for_status()],\n",
        "                                      'parsing_date': [datetime.now().date()],\n",
        "                                      'parsing_time': [datetime.now().time()],\n",
        "                                      'parsing_sec_speed': [time.time() - start_time]})\n",
        "\n",
        "    bs_page = BeautifulSoup(response.text, 'html.parser')\n",
        "  \n",
        "    get_page_stat = open_file_csv(page_s, 'live') # 2. Open file.csv\n",
        "    get_page_stat = pd.concat([get_page_stat, get_page_stat_new])\n",
        "    save_df_file(get_page_stat, page_s, 'live') # 3. Save df to csv file\n",
        "\n",
        "    return bs_page"
      ],
      "metadata": {
        "id": "zOplYaix8RVK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### get_parsing_lists"
      ],
      "metadata": {
        "id": "Ubuse9x_Y-jE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Get links & titles lists (site == url from sites' list for parsing)\n",
        "\n",
        "def get_parsing_lists(site):\n",
        "  sites = open_parsing_dict() # 1. Open dict with sites for parsing\n",
        "  sites_list = [k for k in sites.keys()]\n",
        "  cat_dict = ['news', 'articles'] # topping up list\n",
        "  \n",
        "  links = []\n",
        "  titles = []\n",
        "\n",
        "  for cat in cat_dict:\n",
        "    for k in sites_list:\n",
        "      if k==site:\n",
        "        for i in sites[k]:\n",
        "          if i==cat:\n",
        "            links = list(links + sites[k][i]['links'])\n",
        "            titles = list(titles + sites[k][i]['titles'])\n",
        "  \n",
        "  return links, titles"
      ],
      "metadata": {
        "id": "9EoGmWhr1AmJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### get_pages_counter_stat"
      ],
      "metadata": {
        "id": "JatrYG2TZGLa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### artinvestment.ru"
      ],
      "metadata": {
        "id": "QCaj_UX0QSaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 8.1 Parsing artinvest pages_counter_stat - saving last parsing results from the first pages\n",
        "\n",
        "def get_artinvest_pages_counter_stat(page_url, page, parsing_links, parsing_titles):\n",
        "  start_time = time.time()\n",
        "\n",
        "  # counter block of the page with news list - one for every news' category\n",
        "  table_blocks = page.find_all('div', class_='pager')\n",
        "  # problems can start from here\n",
        "  global df_counter_new\n",
        "  df_counter_new = pd.DataFrame({'page_url': [page_url],\n",
        "                                 'page_title': [parsing_titles[parsing_links.index(page_url)]],\n",
        "                                 'records_total': [int(table_blocks[0].find_all('em')[0].text)],\n",
        "                                 'pages_total': [int(table_blocks[0].find_all('em')[1].text)],\n",
        "                                 'records_max': [int(table_blocks[0].find('input').get('title').split(' ')[1])],\n",
        "                                 'records_value': [int(table_blocks[0].find('input').get('value'))],\n",
        "                                 'first_page_url': [table_blocks[0].find('a').get('href')],\n",
        "                                 'parsing_date': [datetime.now().date()],\n",
        "                                 'parsing_time': [datetime.now().time()],\n",
        "                                 'parsing_sec_speed': [time.time() - start_time]\n",
        "                                 })\n",
        "\n",
        "  return df_counter_new"
      ],
      "metadata": {
        "id": "hqg2VWsIO2Xm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### artchive.ru"
      ],
      "metadata": {
        "id": "zPdD2cb0t4_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 8.2 Parsing artchive pages_counter_stat - saving last parsing results from the first pages\n",
        "\n",
        "def get_artch_pages_counter_stat(page_url, page, parsing_links, parsing_titles):\n",
        "  start_time = time.time()\n",
        "\n",
        "  # counter block of the page with news list - one for every news' category\n",
        "  table_blocks = page.find('div', class_='c_pager')\n",
        "  pattern = re.compile('\\d+')\n",
        "  digits = []\n",
        "  # problems can start from here\n",
        "  try:\n",
        "    for d in pattern.findall(table_blocks.find_all('script')[0].text):\n",
        "      digits.append(int(d))\n",
        "    for d in pattern.findall(table_blocks.find_all('script')[2].text):\n",
        "      digits.append(int(d))\n",
        "  except:\n",
        "    digits = [np.nan, np.nan, np.nan, np.nan, np.nan]\n",
        "\n",
        "  global df_counter_new\n",
        "  df_counter_new = pd.DataFrame({'page_url': [page_url],\n",
        "                                 'page_title': [parsing_titles[parsing_links.index(page_url)]],\n",
        "                                 'records_total': [digits[3]],\n",
        "                                 'pages_total': [digits[0]],\n",
        "                                 'records_max': [digits[4]],\n",
        "                                 'records_value': [np.nan],\n",
        "                                 'first_page_url': [page_url],\n",
        "                                 'parsing_date': [datetime.now().date()],\n",
        "                                 'parsing_time': [datetime.now().time()],\n",
        "                                 'parsing_sec_speed': [time.time() - start_time]\n",
        "                                 })\n",
        "  \n",
        "  return df_counter_new"
      ],
      "metadata": {
        "id": "p9x2idhwtuFP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### artuzel.com"
      ],
      "metadata": {
        "id": "oCingEJrT9He"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 8.3 Parsing artuzel pages_counter_stat - saving last parsing results from the first pages\n",
        "\n",
        "def get_artuz_pages_counter_stat(page_url, page, parsing_links, parsing_titles):\n",
        "  start_time = time.time()\n",
        "\n",
        "  # counter block of the page with news list - one for every news' category\n",
        "  table_blocks = page.find('li', class_='pager-current')\n",
        "  digits = []\n",
        "  # problems can start from here\n",
        "  try:\n",
        "    digits.append(int(table_blocks.get_text().split(' ')[0]))\n",
        "    digits.append(int(table_blocks.get_text().split(' ')[2]))\n",
        "  except:\n",
        "    digits = [np.nan, np.nan]\n",
        "\n",
        "  global df_counter_new\n",
        "  df_counter_new = pd.DataFrame({'page_url': [page_url],\n",
        "                                 'page_title': [parsing_titles[parsing_links.index(page_url)]],\n",
        "                                 'records_total': [np.nan],\n",
        "                                 'pages_total': [digits[1]],\n",
        "                                 'records_max': [np.nan],\n",
        "                                 'records_value': [np.nan],\n",
        "                                 'first_page_url': [page_url],\n",
        "                                 'parsing_date': [datetime.now().date()],\n",
        "                                 'parsing_time': [datetime.now().time()],\n",
        "                                 'parsing_sec_speed': [time.time() - start_time]\n",
        "                                 })\n",
        "  \n",
        "  return df_counter_new"
      ],
      "metadata": {
        "id": "QUcTrGVUT_jX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### get_pages_curr_data"
      ],
      "metadata": {
        "id": "4k0FrIkpZCNm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### artinvestment.ru"
      ],
      "metadata": {
        "id": "lawZgkMDQhXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 9.1 Parsing artinvest current news_articles_data - saving last parsing results from the first pages\n",
        "\n",
        "def get_artinvest_pages_curr_data(page_url, page, parsing_links, parsing_titles):\n",
        "  start_time = time.time()\n",
        "  \n",
        "  # News categories\n",
        "  list_advices = page.find_all('ul', class_='list advices')\n",
        "  # problems can start from here\n",
        "  dates_list = []\n",
        "  for em in list_advices[0].find_all('em'):\n",
        "    dates_list.append(em.text)\n",
        "  links_list = []\n",
        "  titles_list = []\n",
        "  for a in list_advices[0].find_all('a'):\n",
        "    if re.compile('\\d+').search(str(a.get('href')))is not None:\n",
        "      links_list.append(a.get('href'))\n",
        "    if a.get('title') is not None:\n",
        "      titles_list.append(a.get('title'))\n",
        "  short_text_list = []\n",
        "  for span in list_advices[0].find_all('span')[1::2]:\n",
        "    short_text_list.append(span.text)\n",
        "\n",
        "  global df_data_new\n",
        "  df_data_new = pd.DataFrame({'date': dates_list, # date of news\n",
        "                              'link': links_list, # link to news\n",
        "                              'title': titles_list, # title of news\n",
        "                              'short_text': short_text_list, # news' preview\n",
        "                              })\n",
        "  df_data_new['page_url'] = page_url # link to category of news - the same\n",
        "  df_data_new['page_title'] = parsing_titles[parsing_links.index(page_url)] # title of news' category - the same\n",
        "\n",
        "  # For parsing long texts - beginning\n",
        "  df_data_new['long_text_url'] = df_data_new['page_url'] + df_data_new['link']\n",
        "  global long_text_url_list_new\n",
        "  long_text_url_list_new = df_data_new['long_text_url'].tolist()\n",
        "\n",
        "  df_data_new['parsing_date'] = datetime.now().date()\n",
        "  df_data_new['parsing_time'] = datetime.now().time()\n",
        "  df_data_new['parsing_sec_speed'] = time.time() - start_time # without long_text collection\n",
        "\n",
        "  collected_pages_a_count = df_data_new['link'].count()\n",
        "\n",
        "  return df_data_new, long_text_url_list_new, print('{} articles have been collected\\nin {} seconds'.format(collected_pages_a_count, (time.time() - start_time)))"
      ],
      "metadata": {
        "id": "NT9O_dyNAIlP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### theartnewspaper.ru"
      ],
      "metadata": {
        "id": "8xiY6a9-Qx9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 9.2 Parsing tanp current news_articles_data - saving last parsing results from the first pages\n",
        "\n",
        "def get_tanp_pages_curr_data(page_url, page, parsing_links, parsing_titles):\n",
        "  start_time = time.time()\n",
        "  \n",
        "  # News categories\n",
        "  links_list = []\n",
        "  titles_list = []\n",
        "  for prenews in page.find_all('div', class_='postPreviewsV2Root js-fix-post-previews'):\n",
        "    # problems can start from here\n",
        "    for a in prenews.find_all('a'):\n",
        "      links_list.append(a.get('href'))\n",
        "      titles_list.append(a.get('title'))\n",
        "  dates_list = []\n",
        "  for date in page.find_all('div', class_='postPreviewsItemDate'):\n",
        "    # problems can start from here\n",
        "    dates_list.append(date.get_text())\n",
        "  page_title_list = []\n",
        "  page_url_list = []\n",
        "  for p_title in page.find_all('div', class_='postPreviewsItemSection'):\n",
        "    # problems can start from here\n",
        "    page_title_list.append(p_title.get_text())\n",
        "    page_url_list.append(page_url)\n",
        "  short_text_list = []\n",
        "  for s_text in page.find_all('div', class_='postPreviewsItemTitle2 js-fix-hanging js-icon-read-more'):\n",
        "    # problems can start from here\n",
        "    short_text_list.append(s_text.get_text())\n",
        "\n",
        "  global df_data_new\n",
        "  df_data_new = pd.DataFrame({'date': dates_list, # date of news\n",
        "                              'link': links_list, # link to news\n",
        "                              'title': titles_list, # title of news\n",
        "                              'short_text': short_text_list, # news' preview\n",
        "                              'page_url': page_url_list, # link to category of news - the same\n",
        "                              'page_title': page_title_list # title of news' category - not the same\n",
        "                                             })\n",
        "  \n",
        "  # For parsing long texts - beginning\n",
        "  df_data_new['long_text_url'] = df_data_new['page_url'].apply(lambda x: x.split('/')[0] + '//' + x.split('/')[2]) + df_data_new['link']\n",
        "  global long_text_url_list_new\n",
        "  long_text_url_list_new = df_data_new['long_text_url'].tolist()\n",
        "\n",
        "  df_data_new['parsing_date'] = datetime.now().date()\n",
        "  df_data_new['parsing_time'] = datetime.now().time()\n",
        "  df_data_new['parsing_sec_speed'] = time.time() - start_time # without long_text collection\n",
        "\n",
        "  collected_pages_a_count = df_data_new['link'].count()\n",
        "\n",
        "  return df_data_new, long_text_url_list_new, print('{} articles have been collected\\nin {} seconds'.format(collected_pages_a_count, (time.time() - start_time)))"
      ],
      "metadata": {
        "id": "E7hA5RLhQxdZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### artchive.ru"
      ],
      "metadata": {
        "id": "7HU1j885uA9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 9.3 Parsing artchive current news_articles_data - saving last parsing results from the first pages\n",
        "\n",
        "def get_artch_pages_curr_data(page_url, page, parsing_links, parsing_titles):\n",
        "  start_time = time.time()\n",
        "  \n",
        "  # News categories\n",
        "  items_block = page.find('div', class_='knowledge-list').find_all('div', class_='item')\n",
        "  \n",
        "  links_list = []\n",
        "  titles_list = []\n",
        "  short_text_list = []\n",
        "  for item in items_block:\n",
        "    # problems can start from here\n",
        "    links_list.append(item.find('div', class_='item-announce').find('a').get('href'))\n",
        "    titles_list.append(item.find('div', class_='item-announce').find('a').get_text())\n",
        "    short_text_list.append(item.find('div', class_='item-announce').find('a').get_text())\n",
        "  dates_list = []\n",
        "  for date in items_block:\n",
        "    # problems can start from here\n",
        "    try:\n",
        "      dates_list.append(pd.to_datetime(date.find('div', class_='item-date').find('time').get('datetime')).date())\n",
        "    except: \n",
        "      dates_list.append(datetime.now().date())\n",
        "  page_title_list = []\n",
        "  page_url_list = []\n",
        "  for tag in items_block:\n",
        "    page_url_list.append(page_url)\n",
        "    try:\n",
        "      page_title_list.append(tag.find('div', class_='item-tags').find_all('a')[0].get_text())\n",
        "    except:\n",
        "      page_title_list.append(parsing_titles[parsing_links.index(page_url)])\n",
        "\n",
        "  global df_data_new\n",
        "  df_data_new = pd.DataFrame({'date': dates_list, # date of news\n",
        "                              'link': links_list, # link to news\n",
        "                              'title': titles_list, # title of news\n",
        "                              'short_text': short_text_list, # news' preview\n",
        "                              'page_url': page_url_list, # link to category of news - the same\n",
        "                              'page_title': page_title_list # title of news' category - not the same\n",
        "                              })\n",
        "  \n",
        "  # For parsing long texts - beginning\n",
        "  df_data_new['long_text_url'] = df_data_new['page_url'].apply(lambda x: x.split('/')[0] + '//' + x.split('/')[2]) + df_data_new['link']\n",
        "  global long_text_url_list_new\n",
        "  long_text_url_list_new = df_data_new['long_text_url'].tolist()\n",
        "\n",
        "  df_data_new['parsing_date'] = datetime.now().date()\n",
        "  df_data_new['parsing_time'] = datetime.now().time()\n",
        "  df_data_new['parsing_sec_speed'] = time.time() - start_time # without long_text collection\n",
        "\n",
        "  collected_pages_a_count = df_data_new['link'].count()\n",
        "\n",
        "  return df_data_new, long_text_url_list_new, print('{} articles have been collected\\nin {} seconds'.format(collected_pages_a_count, (time.time() - start_time)))"
      ],
      "metadata": {
        "id": "fGQsfEWmuE0W"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### artuzel.com"
      ],
      "metadata": {
        "id": "Wt8ajitlUMqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 9.4 Parsing artuzel current news_articles_data - saving last parsing results from the first pages\n",
        "\n",
        "def get_artuz_pages_curr_data(page_url, page, parsing_links, parsing_titles):\n",
        "  start_time = time.time()\n",
        "  \n",
        "  # News categories\n",
        "  items_block = page.find_all('div', class_='view-content')[0].find_all('a')\n",
        "  \n",
        "  links_list = []\n",
        "  titles_list = []\n",
        "  short_text_list = []\n",
        "  for item in items_block[:20]: # very few sections have pages (20 articles on each), the others contain all articles accumulatively !!!\n",
        "  #for item in items_block: # !!! only for collecting the ARCHIVE !!!\n",
        "    # problems can start from here\n",
        "    links_list.append(item.get('href'))\n",
        "    titles_list.append(item.find('div', class_='view-exhibitions-title').get_text())\n",
        "    short_text_list.append(item.find('div', class_='view-exhibitions-body').get_text())\n",
        "  dates_list = []\n",
        "  for date in items_block[:20]: # very few sections have pages (20 articles on each), the others contain all articles accumulatively !!!\n",
        "  #for date in items_block: # !!! only for collecting the ARCHIVE !!!\n",
        "    # problems can start from here\n",
        "    try:\n",
        "      d = date.find('div', class_='views-field-field-created').get_text().split(',')[1]\n",
        "      dates_list.append(d.split(' ')[1] + '.' + rus_mon_dict[d.split(' ')[2][:3]] + '.' + d.split(' ')[3])\n",
        "    except:\n",
        "      try:\n",
        "        d = date.find('span', class_='date-display-single').get_text().split(',')[1]\n",
        "        dates_list.append(d.split(' ')[1] + '.' + rus_mon_dict[d.split(' ')[2][:3]] + '.' + d.split(' ')[3])\n",
        "      except: \n",
        "        dates_list.append(datetime.now().date())\n",
        "\n",
        "  global df_data_new\n",
        "  df_data_new = pd.DataFrame({'date': dates_list, # date of news\n",
        "                              'link': links_list, # link to news\n",
        "                              'title': titles_list, # title of news\n",
        "                              'short_text': short_text_list # news' preview\n",
        "                              })\n",
        "  df_data_new['page_url'] = page_url # link to category of news - the same\n",
        "  df_data_new['page_title'] = parsing_titles[parsing_links.index(page_url)] # title of news' category - the same\n",
        "\n",
        "  \n",
        "  # For parsing long texts - beginning\n",
        "  df_data_new['long_text_url'] = df_data_new['page_url'].apply(lambda x: x.split('/')[0] + '//' + x.split('/')[2]) + df_data_new['link']\n",
        "  global long_text_url_list_new\n",
        "  long_text_url_list_new = df_data_new['long_text_url'].tolist()\n",
        "\n",
        "  df_data_new['parsing_date'] = datetime.now().date()\n",
        "  df_data_new['parsing_time'] = datetime.now().time()\n",
        "  df_data_new['parsing_sec_speed'] = time.time() - start_time # without long_text collection\n",
        "\n",
        "  collected_pages_a_count = df_data_new['link'].count()\n",
        "\n",
        "  return df_data_new, long_text_url_list_new, print('{} articles have been collected\\nin {} seconds'.format(collected_pages_a_count, (time.time() - start_time)))"
      ],
      "metadata": {
        "id": "wW5hwzJ-UNs_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### get_long_text"
      ],
      "metadata": {
        "id": "4Nu7LwVhZRpq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### artinvestment.ru"
      ],
      "metadata": {
        "id": "2YAmoM1aQ-Xn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10.1 Parsing artinvest long texts - saving only new results from the first pages\n",
        "    \n",
        "def get_artinvest_long_text(text_page):\n",
        "  start_time = time.time()\n",
        "\n",
        "  p_block = text_page.find('div', class_='block white').find_all('p')\n",
        "  f_block = text_page.find('div', class_='block white').find_all('figure')\n",
        "  sp_block = text_page.find('div', class_='block white').find_all('span')\n",
        "\n",
        "  global long_text_list_new\n",
        "  long_text_list_new = []\n",
        "  global headings_list_new\n",
        "  headings_list_new = []\n",
        "  try:\n",
        "    long_text_list_new.append(text_page.find('div', class_='block white').find('h1').get_text())\n",
        "    headings_list_new.append(text_page.find('div', class_='block white').find('h1').get_text())\n",
        "    for p in p_block:\n",
        "      long_text_list_new.append(p.text) # the whole text\n",
        "      try:\n",
        "        for a in p.find_all('a'):\n",
        "          if a not in headings_list_new:\n",
        "            headings_list_new.append(a.get_text()) # links' title\n",
        "      except: continue\n",
        "      try:\n",
        "        for s in p.find_all('strong'):\n",
        "          if s not in headings_list_new:\n",
        "            headings_list_new.append(s.get_text()) # bold text\n",
        "      except: continue\n",
        "  except: pass\n",
        "\n",
        "  global images_list_new\n",
        "  images_list_new = []\n",
        "  try:\n",
        "    try:\n",
        "      for sp in sp_block:\n",
        "        images_list_new.append(sp.find('img').get('src'))\n",
        "        images_list_new.append(sp.text)\n",
        "    except:\n",
        "      for f in f_block:\n",
        "        images_list_new.append(f.find('img').get('src'))\n",
        "        images_list_new.append(f.find('a').get('title'))\n",
        "  except: pass\n",
        "\n",
        "  global sourses_list_new\n",
        "  sourses_list_new = []\n",
        "  try:\n",
        "    for t in text_page.find('div', class_='block content-data article-content').find('p', class_='mat2left').find_all('a'):\n",
        "      sourses_list_new.append(t.get('href'))\n",
        "  except: pass\n",
        "\n",
        "  global tags_list_new\n",
        "  tags_list_new = []\n",
        "  \n",
        "  global parsing_speed_list_new\n",
        "  parsing_speed_list_new = [(time.time() - start_time)]\n",
        "\n",
        "  return long_text_list_new, headings_list_new, images_list_new, sourses_list_new, tags_list_new, parsing_speed_list_new"
      ],
      "metadata": {
        "id": "SsDaS5g_MitB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### theartnewspaper.ru"
      ],
      "metadata": {
        "id": "HSOUA5-3RNWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10.2 Parsing tanp long texts - saving only new results from the first pages\n",
        "    \n",
        "def get_tanp_long_text(text_page):\n",
        "  start_time = time.time()\n",
        "\n",
        "  t_block = text_page.find_all('div', class_='leftCol630')\n",
        "  img_block = text_page.find_all('div', class_='leftCol')[4].find_all('img') # !!!\n",
        "  tag_block = text_page.find('div', class_='postSectionsRoot').find_all('a')\n",
        "\n",
        "  # new part\n",
        "  global tags_list_new\n",
        "  tags_list_new = []\n",
        "  try:\n",
        "    for tag in tag_block:\n",
        "      tags_list_new.append(tag.get('href'))\n",
        "      tags_list_new.append(tag.get_text())\n",
        "  except: pass\n",
        "\n",
        "  # different code\n",
        "  global long_text_list_new\n",
        "  long_text_list_new = []\n",
        "  global headings_list_new\n",
        "  headings_list_new = []\n",
        "  # 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'div' class_='postListItemTitleRoot', 'b', 'blockquote'\n",
        "  try:\n",
        "    for t in t_block:\n",
        "      long_text_list_new.append(t.get_text())\n",
        "      for h in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:\n",
        "        h_block = t.find_all(h)\n",
        "        try:\n",
        "          for h_str in h_block:\n",
        "            if h_str not in headings_list_new:\n",
        "              headings_list_new.append(h_str.get_text())\n",
        "        except: continue\n",
        "      div_block = t.find_all('div', class_='postListItemTitleRoot')\n",
        "      try:\n",
        "        for d_str in div_block:\n",
        "          if d_str not in headings_list_new:\n",
        "            headings_list_new.append(d_str.get_text())\n",
        "      except: pass\n",
        "      for b in ['b', 'blockquote']:\n",
        "        b_block = t.find_all(b)\n",
        "        try:\n",
        "          for b_str in b_block:\n",
        "            if b_str not in headings_list_new:\n",
        "              headings_list_new.append(b_str.get_text())\n",
        "        except: continue\n",
        "  except: pass\n",
        "\n",
        "  global images_list_new\n",
        "  images_list_new = []\n",
        "  try:\n",
        "    for img in img_block:\n",
        "      if len(img.get('alt')) != 0:\n",
        "        images_list_new.append(img.get('src'))\n",
        "        images_list_new.append(img.get('alt'))\n",
        "  except: pass\n",
        "\n",
        "  global sourses_list_new\n",
        "  sourses_list_new = []\n",
        "  global parsing_speed_list_new\n",
        "  parsing_speed_list_new = [(time.time() - start_time)]\n",
        "\n",
        "  return long_text_list_new, headings_list_new, images_list_new, sourses_list_new, tags_list_new, parsing_speed_list_new"
      ],
      "metadata": {
        "id": "wZlk-k3aRM9q"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### artchive.ru"
      ],
      "metadata": {
        "id": "XPFAoLS0uCqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10.3 Parsing artch long texts - saving only new results from the first pages\n",
        "    \n",
        "def get_artch_long_text(text_page):\n",
        "  start_time = time.time()\n",
        "\n",
        "  t_block = text_page.find('div', class_='article').find_all('div', class_='text-block')\n",
        "  st_block = text_page.find('div', class_='article').find_all('div', class_='strong-text')\n",
        "  img_block = text_page.find('div', class_='article').find_all('div', class_='c_img ')\n",
        "  tag_block = text_page.find('div', class_='article').find('div', 'content-footer__tags')\n",
        "\n",
        "  # different code\n",
        "  global tags_list_new\n",
        "  tags_list_new = []\n",
        "  try:\n",
        "    for tag in tag_block.find_all('a'):\n",
        "      tags_list_new.append(tag.get('href'))\n",
        "      tags_list_new.append(tag.get_text()[1:])\n",
        "  except: pass\n",
        "\n",
        "  global long_text_list_new\n",
        "  long_text_list_new = []\n",
        "  global headings_list_new\n",
        "  headings_list_new = [] # 'Читать дальше\\n' !!!!!!!!!!!!!!\n",
        "  # 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'div' class_='postListItemTitleRoot', 'b', 'blockquote'\n",
        "  try:\n",
        "    long_text_list_new.append(text_page.find('div', class_='article').find('h1').get_text())\n",
        "    headings_list_new.append(text_page.find('div', class_='article').find('h1').get_text())\n",
        "    for t in t_block:\n",
        "      add_news = t.find('div', class_='news-link')\n",
        "      try:\n",
        "        len(add_news.get_text())\n",
        "      except:\n",
        "        long_text_list_new.append(t.get_text())\n",
        "        for h in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:\n",
        "          h_block = t.find_all(h)\n",
        "          try:\n",
        "            for h_str in h_block:\n",
        "              if h_str not in headings_list_new:\n",
        "                headings_list_new.append(h_str.get_text())\n",
        "          except: continue\n",
        "        a_block = t.find_all('a')\n",
        "        try:\n",
        "          for a_str in a_block:\n",
        "            if a_str not in headings_list_new:\n",
        "              headings_list_new.append(a_str.get_text())\n",
        "        except: pass\n",
        "        for b in ['b', 'blockquote']:\n",
        "          b_block = t.find_all(b)\n",
        "          try:\n",
        "            for b_str in b_block:\n",
        "              if b_str not in headings_list_new:\n",
        "                headings_list_new.append(b_str.get_text())\n",
        "          except: continue\n",
        "          try:\n",
        "            for st in st_block:\n",
        "              if st not in headings_list_new:\n",
        "              #long_text_list_new.append(st.get_text()) # because of sourse\n",
        "                headings_list_new.append(st.get_text())\n",
        "          except: pass\n",
        "  except: pass\n",
        "\n",
        "  l='Читать дальше\\n' # don't work correctly\n",
        "  for el in headings_list_new:\n",
        "    if el==l:\n",
        "      headings_list_new.remove(el)\n",
        "\n",
        "  global images_list_new\n",
        "  images_list_new = []\n",
        "  # title can be not full\n",
        "  # don't collect 'post-art test-two-arts' divs\n",
        "  try:\n",
        "    for img in img_block:\n",
        "      images_list_new.append(img.find('img').get('src'))\n",
        "      images_list_new.append(img.find('img').get('title'))\n",
        "  except: pass\n",
        "\n",
        "  global sourses_list_new\n",
        "  sourses_list_new = []\n",
        "  pattern = re.compile('По материалам ')\n",
        "  string = long_text_list_new[-1].replace('\\xa0', ' ')\n",
        "  if type(pattern.match(string)) is re.Match:\n",
        "    sourses_list_new.append(string.replace('По материалам ', ''))\n",
        "  \n",
        "  global parsing_speed_list_new\n",
        "  parsing_speed_list_new = [(time.time() - start_time)]\n",
        "\n",
        "  return long_text_list_new, headings_list_new, images_list_new, sourses_list_new, tags_list_new, parsing_speed_list_new"
      ],
      "metadata": {
        "id": "DLnvOkq5uXst"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### artuzel.com"
      ],
      "metadata": {
        "id": "YcER4cIDaTi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10.4 Parsing artuzel long texts - saving only new results from the first pages\n",
        "    \n",
        "def get_artuz_long_text(text_page):\n",
        "  start_time = time.time()\n",
        "\n",
        "  t_block = text_page.find('div', class_='content clearfix').find_all('p')\n",
        "  img_block = text_page.find('div', class_='content clearfix').find_all('img')\n",
        "  tag_block = text_page.find('ul', class_='links inline')\n",
        "\n",
        "  # different code\n",
        "  global tags_list_new\n",
        "  tags_list_new = []\n",
        "  try:\n",
        "    for tag in tag_block.find_all('a'):\n",
        "      tags_list_new.append(tag.get('href'))\n",
        "      tags_list_new.append(tag.get_text())\n",
        "  except: pass\n",
        "\n",
        "  global long_text_list_new\n",
        "  long_text_list_new = []\n",
        "  global headings_list_new\n",
        "  headings_list_new = []\n",
        "  # date of the news - for replacing in current data\n",
        "  # new part\n",
        "  d = text_page.find('div', class_='meta submitted').get_text().split(',')[1]\n",
        "  headings_list_new.append(d.split(' ')[1] + '.' + rus_mon_dict[d.split(' ')[2][:3]] + '.' + d.split(' ')[3])\n",
        "  \n",
        "  # 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'div' class_='postListItemTitleRoot', 'b', 'blockquote'\n",
        "  try:\n",
        "    long_text_list_new.append(text_page.find('h1', id='page-title').get_text())\n",
        "    headings_list_new.append(text_page.find('h1', id='page-title').get_text())\n",
        "    for t in t_block:\n",
        "      long_text_list_new.append(t.get_text())\n",
        "      for h in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:\n",
        "        h_block = t.find_all(h)\n",
        "        try:\n",
        "          for h_str in h_block:\n",
        "            if h_str not in headings_list_new:\n",
        "              headings_list_new.append(h_str.get_text())\n",
        "        except: continue\n",
        "      for b in ['strong', 'span', 'em', 'b']:\n",
        "        b_block = t.find_all(b)\n",
        "        try:\n",
        "          for b_str in b_block:\n",
        "            if b_str not in headings_list_new:\n",
        "              headings_list_new.append(b_str.get_text())\n",
        "        except: continue\n",
        "\n",
        "  except: pass\n",
        "\n",
        "  global images_list_new\n",
        "  images_list_new = []\n",
        "  # title can be not full\n",
        "  try:\n",
        "    for img in img_block:\n",
        "      images_list_new.append(img.get('src'))\n",
        "      try:\n",
        "        images_list_new.append(img.get('title'))\n",
        "      except:\n",
        "        images_list_new.append('')\n",
        "  except: pass\n",
        "\n",
        "  global sourses_list_new\n",
        "  sourses_list_new = []\n",
        "  global parsing_speed_list_new\n",
        "  parsing_speed_list_new = [(time.time() - start_time)]\n",
        "\n",
        "  return long_text_list_new, headings_list_new, images_list_new, sourses_list_new, tags_list_new, parsing_speed_list_new"
      ],
      "metadata": {
        "id": "5BzIyL0eaUej"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### news_articles_data ARCHIVE"
      ],
      "metadata": {
        "id": "yhA4d5CqHZv7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### artinvestment.ru"
      ],
      "metadata": {
        "id": "s4PJOY4hHd9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 13.1 Parsing artinvest news_articles_data ARCHIVE\n",
        "def get_artinvest_next_page_url_list(first_page_url, pages_total):\n",
        "\n",
        "  url_part_1 = first_page_url.split('=')[0]\n",
        "  url_part_2 = first_page_url.split('=')[1].split('&')[1]\n",
        "  url_part_3 = first_page_url.split('=')[2]\n",
        "\n",
        "  global next_page_url_list_new\n",
        "  next_page_url_list_new = []\n",
        "  for p in range(2, pages_total+1):\n",
        "    next_page_url = url_part_1 + '=' + str(p) + '&' + url_part_2 + '=' + url_part_3\n",
        "    next_page_url_list_new.append(next_page_url)\n",
        "\n",
        "  return next_page_url_list_new"
      ],
      "metadata": {
        "id": "slgDbnMuF_Sj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### artchive.ru"
      ],
      "metadata": {
        "id": "zwBQJDVaH3y7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 13.2 Parsing artchive news_articles_data ARCHIVE\n",
        "def get_artch_next_page_url_list(first_page_url, pages_total):\n",
        "\n",
        "  global next_page_url_list_new\n",
        "  next_page_url_list_new = []\n",
        "  for p in range(2, pages_total+1):\n",
        "    url_split = first_page_url.split('/')\n",
        "    try:\n",
        "      if first_page_url.split('/')[4][:6]=='rubric':\n",
        "        next_page_url = url_split[0]+'//'+url_split[2]+'/'+url_split[3]+'/p:'+str(p)+'-'+url_split[4]\n",
        "      else:\n",
        "        next_page_url = first_page_url + '/p:' + str(p)\n",
        "    except:\n",
        "      next_page_url = first_page_url + '/p:' + str(p)\n",
        "\n",
        "    next_page_url_list_new.append(next_page_url)\n",
        "\n",
        "  return next_page_url_list_new"
      ],
      "metadata": {
        "id": "1nZZ6Wj7H42d"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### artuzel.com"
      ],
      "metadata": {
        "id": "Hn9sGo8L696t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 13.3 Parsing artuzel news_articles_data ARCHIVE\n",
        "def get_artuz_next_page_url_list(first_page_url, pages_total):\n",
        "\n",
        "  global next_page_url_list_new\n",
        "  next_page_url_list_new = []\n",
        "\n",
        "  if pages_total > 1.0:\n",
        "    for p in range(1, int(pages_total)):\n",
        "      url_split = first_page_url.split('/')\n",
        "      next_page_url = url_split[0]+'//'+url_split[2]+'/'+url_split[3]+'?page='+str(p)\n",
        "      next_page_url_list_new.append(next_page_url)\n",
        "  else:\n",
        "    next_page_url_list_new.append(first_page_url)\n",
        "\n",
        "  return next_page_url_list_new"
      ],
      "metadata": {
        "id": "AKQ-T_Js7A0M"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions aggrigators"
      ],
      "metadata": {
        "id": "LkJys8hRRiob"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### parsing_agg_sd()"
      ],
      "metadata": {
        "id": "ATJJ_e8SRmBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### Step 1\n",
        "# 11.1 Getting pages_counter_stat, pages_curr_data csv files and json long_text_url_list_temp\n",
        "\n",
        "def parsing_agg_sd(site, s_file, d_file, lt_file):\n",
        "\n",
        "  parsing_links_list, parsing_titles_list = get_parsing_lists(site) # 7. Get links & titles\n",
        "                                           #get_parsing_lists(site)\n",
        "\n",
        "  try:\n",
        "    df_counter = open_file_csv(s_file, 'live') # 2. Open file.csv\n",
        "    df_counter['parsing_date'] = df_counter['parsing_date'].dropna().apply(lambda x: date_transfomation(x)) # 14. Date transfomation\n",
        "  except: pass\n",
        "\n",
        "  df_data = open_file_csv(d_file, 'live') # 2. Open file.csv\n",
        "  df_data['parsing_date'] = df_data['parsing_date'].dropna().apply(lambda x: date_transfomation(x)) # 14. Date transfomation\n",
        "  \n",
        "  # For parsing long texts\n",
        "  long_text_url_list = []\n",
        "\n",
        "  for link in parsing_links_list: # page with news list of certain category\n",
        "    link_page = get_page(link) # 1. Collect request status\n",
        "\n",
        "    # for artinvestment.ru\n",
        "    if d_file == artinvest_d:\n",
        "\n",
        "      # counter block of the page with news list - one for every news' category\n",
        "      # 8.1 Parsing artinvest pages_counter_stat\n",
        "      get_artinvest_pages_counter_stat(link, link_page, parsing_links_list, parsing_titles_list)\n",
        "      df_counter = pd.concat([df_counter, df_counter_new]) # + one line to the df\n",
        "\n",
        "      # 9.1 Parsing artinvest current news_articles_data\n",
        "      get_artinvest_pages_curr_data(link, link_page, parsing_links_list, parsing_titles_list)\n",
        "      \n",
        "      df_data = pd.concat([df_data, df_data_new])\n",
        "      long_text_url_list = list(long_text_url_list + long_text_url_list_new)\n",
        "\n",
        "    # for theartnewspaper.ru\n",
        "    elif d_file == theartnewspaper_d:\n",
        "\n",
        "      # 9.2 Parsing tanp current news_articles_data\n",
        "      get_tanp_pages_curr_data(link, link_page, parsing_links_list, parsing_titles_list)\n",
        "      \n",
        "      df_data = pd.concat([df_data, df_data_new])\n",
        "      long_text_url_list = list(long_text_url_list + long_text_url_list_new)\n",
        "\n",
        "    # for artchive.ru\n",
        "    elif d_file == artchive_d:\n",
        "\n",
        "      # 8.2 Parsing artchive pages_counter_stat\n",
        "      get_artch_pages_counter_stat(link, link_page, parsing_links_list, parsing_titles_list)\n",
        "      df_counter = pd.concat([df_counter, df_counter_new]) # + one line to the df\n",
        "\n",
        "      # 9.3 Parsing artch current news_articles_data\n",
        "      get_artch_pages_curr_data(link, link_page, parsing_links_list, parsing_titles_list)\n",
        "      \n",
        "      df_data = pd.concat([df_data, df_data_new])\n",
        "      long_text_url_list = list(long_text_url_list + long_text_url_list_new)\n",
        "\n",
        "    # for artuzel.com\n",
        "    elif d_file == artuzel_d:\n",
        "\n",
        "      # 8.3 Parsing artuzel pages_counter_stat\n",
        "      get_artuz_pages_counter_stat(link, link_page, parsing_links_list, parsing_titles_list)\n",
        "      df_counter = pd.concat([df_counter, df_counter_new]) # + one line to the df\n",
        "\n",
        "      # 9.4 Parsing artuzel current news_articles_data\n",
        "      get_artuz_pages_curr_data(link, link_page, parsing_links_list, parsing_titles_list)\n",
        "      \n",
        "      df_data = pd.concat([df_data, df_data_new])\n",
        "      long_text_url_list = list(long_text_url_list + long_text_url_list_new)\n",
        "\n",
        "    #### loop ending\n",
        "\n",
        "  try:\n",
        "    df_counter.drop_duplicates(subset = ['page_url', 'parsing_date'], keep = 'last', inplace = True)\n",
        "    save_df_file(df_counter, s_file, 'live') # 3. Save df to csv file\n",
        "    df_counter['site'] = df_counter['page_url'].apply(lambda x: x.split('/')[0] + '//' + x.split('/')[2] + '/')\n",
        "    new_pages_count = df_counter.loc[(df_counter['parsing_date']==datetime.now().date())&(df_counter['site']==site)]['page_url'].count()\n",
        "\n",
        "    result = '{} new counter blocks have been collected\\nAll counter blocks have been collected - {}'.format(new_pages_count, (new_pages_count==len(parsing_links_list)))\n",
        "\n",
        "  except:\n",
        "    result = 'No counter block exists'\n",
        "\n",
        "  # For parsing long texts - continueing\n",
        "  save_long_text_url_list_temp(long_text_url_list) # 5. Save json long_text_url_list_temp\n",
        "\n",
        "  df_data.drop_duplicates(subset = 'long_text_url', keep = 'first', inplace = True) # was keep = 'last' before\n",
        "  save_df_file(df_data, d_file, 'live') # 3. Save df to csv file\n",
        "\n",
        "  time.sleep(5) # time for renewing json artinvest_long_text_url_list_temp\n",
        "  parsing_agg_lt(lt_file) # 11.2 Getting long texts files\n",
        "    \n",
        "  return print(result)"
      ],
      "metadata": {
        "id": "iNThl4NXRnB_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### parsing_agg_lt()"
      ],
      "metadata": {
        "id": "YVsmylI0Rxpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### Step 2\n",
        "# 11.2 Getting long texts files\n",
        "\n",
        "def parsing_agg_lt(lt_file):\n",
        "\n",
        "  long_text_df = open_file_csv(lt_file, 'live') # 2. Open file.csv\n",
        "  long_text_url_list_old = long_text_df['long_text_url'].tolist()\n",
        "  long_text_url_list_temp = open_long_text_url_list_temp() # 4. Open json long_text_url_list_temp\n",
        "  long_text_url_list_curr = list(set(long_text_url_list_temp) - set(long_text_url_list_old)) # only new urls - temporal list\n",
        "\n",
        "  long_text_list = []\n",
        "  headings_list = []\n",
        "  images_list = []\n",
        "  sourses_list = []\n",
        "  tags_list = []\n",
        "  parsing_speed_list = []\n",
        "\n",
        "  for url in long_text_url_list_curr: # one article from certane category news list\n",
        "    page = get_page(url) # 1. Collect request status\n",
        "\n",
        "    # for artinvestment.ru\n",
        "    if lt_file == artinvest_lt:\n",
        "      get_artinvest_long_text(page) # 10.1 Parsing artinvest long texts\n",
        "     \n",
        "    # for theartnewspaper.ru\n",
        "    elif lt_file == theartnewspaper_lt:\n",
        "      get_tanp_long_text(page) # 10.2 Parsing theartnewspaper long texts\n",
        "\n",
        "    # for artchive.ru\n",
        "    elif lt_file == artchive_lt:\n",
        "      get_artch_long_text(page) # 10.3 Parsing artchive long texts\n",
        "\n",
        "    # for artuzel.com\n",
        "    elif lt_file == artuzel_lt:\n",
        "      get_artuz_long_text(page) # 10.4 Parsing artuzel long texts\n",
        "\n",
        "    long_text_list.append(long_text_list_new)\n",
        "    headings_list.append(headings_list_new)\n",
        "    images_list.append(images_list_new)\n",
        "    sourses_list.append(sourses_list_new)\n",
        "    tags_list.append(tags_list_new)\n",
        "    parsing_speed_list.append(parsing_speed_list_new)\n",
        "\n",
        "  #### loop ending\n",
        "\n",
        "  long_text_df_new = pd.DataFrame({'long_text_url': long_text_url_list_curr,\n",
        "                                   'long_text': long_text_list,\n",
        "                                   'structure': headings_list,\n",
        "                                   'images': images_list,\n",
        "                                   'sourses': sourses_list,\n",
        "                                   'tags': tags_list,\n",
        "                                   'parsing_sec_speed_2': parsing_speed_list # for long_text collection without getting page\n",
        "                                   })\n",
        "  \n",
        "  collected_pages_t_count = long_text_df_new['long_text_url'].count()\n",
        "  long_text_df = pd.concat([long_text_df, long_text_df_new])\n",
        "  long_text_df.drop_duplicates(subset = 'long_text_url', keep = 'first', inplace = True)\n",
        "\n",
        "  save_df_file(long_text_df, lt_file, 'live') # 3. Save df to csv file\n",
        "\n",
        "  return print('{} text pages have been collected\\nAll text pages have been collected - {}'.format(collected_pages_t_count, collected_pages_t_count==len(long_text_url_list_curr)))"
      ],
      "metadata": {
        "id": "MXOIf7ITRzj2"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### parsing_agg_a_n_archive"
      ],
      "metadata": {
        "id": "lcwdj8ETZYpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 11.3 Parsing news_articles_data ARCHIVE - particular category separately (p_url) after checking, last parsing\n",
        "\n",
        "def parsing_agg_a_n_archive(s_file, d_file, lt_file, p_url):\n",
        "  df_counter_arch = open_file_csv(s_file, 'live') # 2. Open file.csv - counter_stat\n",
        "  df_counter_arch['parsing_date'] = df_counter_arch['parsing_date'].dropna().apply(lambda x: date_transfomation(x)) # 14. Date transfomation\n",
        "  df_counter_arch = df_counter_arch.loc[(df_counter_arch['page_url']==p_url)&(df_counter_arch['parsing_date']==df_counter_arch['parsing_date'].max())]\n",
        "\n",
        "  df_data = open_file_csv(d_file, 'live') # 2. Open file.csv - current data\n",
        "  df_data['parsing_date'] = df_data['parsing_date'].dropna().apply(lambda x: date_transfomation(x)) # 14. Date transfomation\n",
        "\n",
        "  # For parsing current artinvest_news_articles_data\n",
        "  pars_links_list = df_counter_arch['page_url'].tolist()\n",
        "  pars_titles_list = df_counter_arch['page_title'].tolist()\n",
        "  # For next_page_url_list\n",
        "  first_page_url = df_counter_arch['first_page_url'].unique()[0]\n",
        "  pages_total = df_counter_arch['pages_total'].unique()[0]\n",
        "\n",
        "  next_page_url_list = []\n",
        "\n",
        "  # for artinvestment.ru\n",
        "  if d_file == artinvest_d:\n",
        "    # 13.1 Parsing artinvest news_articles_data ARCHIVE\n",
        "    get_artinvest_next_page_url_list(first_page_url, pages_total)\n",
        "    next_page_url_list = list(next_page_url_list + next_page_url_list_new)\n",
        "  \n",
        "  # for artchive.ru\n",
        "  elif d_file == artchive_d:\n",
        "    # 13.2 Parsing artchive news_articles_data ARCHIVE\n",
        "    get_artch_next_page_url_list(first_page_url, pages_total)\n",
        "    next_page_url_list = list(next_page_url_list + next_page_url_list_new)\n",
        "\n",
        "  # for artuzel.com\n",
        "  elif d_file == artuzel_d:\n",
        "    # 13.3 Parsing artuzel news_articles_data ARCHIVE\n",
        "    get_artuz_next_page_url_list(first_page_url, pages_total)\n",
        "    next_page_url_list = list(next_page_url_list + next_page_url_list_new)\n",
        "\n",
        "  #### loop ending\n",
        "\n",
        "  # For parsing long texts\n",
        "  long_text_url_list = []\n",
        "\n",
        "  for np_url in next_page_url_list:\n",
        "    try:\n",
        "      page = get_page(np_url) # 1. Collect request status\n",
        "\n",
        "      # for artinvestment.ru\n",
        "      if d_file == artinvest_d:   \n",
        "        # 9.1 Parsing artinvestment current news_articles_data\n",
        "        get_artinvest_pages_curr_data(p_url, page, pars_links_list, pars_titles_list)\n",
        "      \n",
        "        df_data = pd.concat([df_data, df_data_new])\n",
        "        long_text_url_list = list(long_text_url_list + long_text_url_list_new)\n",
        "    \n",
        "      # for artchive.ru\n",
        "      elif d_file == artchive_d:\n",
        "        # 9.3 Parsing artchive current news_articles_data\n",
        "        get_artch_pages_curr_data(p_url, page, pars_links_list, pars_titles_list)\n",
        "      \n",
        "        df_data = pd.concat([df_data, df_data_new])\n",
        "        long_text_url_list = list(long_text_url_list + long_text_url_list_new)\n",
        "\n",
        "      # for artuzel.com\n",
        "      elif d_file == artuzel_d:\n",
        "        # 9.4 Parsing artuzel current news_articles_data\n",
        "        get_artuz_pages_curr_data(p_url, page, pars_links_list, pars_titles_list)\n",
        "      \n",
        "        df_data = pd.concat([df_data, df_data_new])\n",
        "        long_text_url_list = list(long_text_url_list + long_text_url_list_new)\n",
        "    \n",
        "    except: continue\n",
        "    #### loop ending\n",
        "\n",
        "  # For parsing long texts - continueing\n",
        "  save_long_text_url_list_temp(long_text_url_list) # 5. Save json long_text_url_list_temp\n",
        "\n",
        "  df_data.drop_duplicates(subset = 'long_text_url', keep = 'first', inplace = True) # was keep = 'last' before\n",
        "  save_df_file(df_data, d_file, 'live') # 3. Save df to csv file\n",
        "\n",
        "  time.sleep(5) # time for renewing json artinvest_long_text_url_list_temp\n",
        "  parsing_agg_lt(lt_file) # 11.2 Getting long texts files"
      ],
      "metadata": {
        "id": "M2osYMYZ-oX1"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### long_text_problems_fix"
      ],
      "metadata": {
        "id": "eDttnJ8VZV8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. Fixing long text problems\n",
        "\n",
        "def long_text_problems_fix(lt_file, df):\n",
        "  cheking_long_text_list = []\n",
        "  # Step 1\n",
        "  for url in df.loc[df['long_text'].isna()==True]['long_text_url']:\n",
        "    cheking_long_text_list.append(url)\n",
        "  # Step 2\n",
        "  df = df.loc[df['long_text'].isna()==False]\n",
        "  df['long_text_len'] = df['long_text'].apply(lambda x: len(x[1:-1]))\n",
        "  for url in df.loc[df['long_text_len']==0]['long_text_url']:\n",
        "    cheking_long_text_list.append(url)\n",
        "  #del copy_df\n",
        "  #gc.collect()\n",
        "\n",
        "  delta = len(cheking_long_text_list)\n",
        "\n",
        "  if delta == 0:\n",
        "    result = 'All long texts were found'\n",
        "  else:\n",
        "    long_text_url_visited = len(page_statistic.loc[page_statistic['page_url'].isin(cheking_long_text_list)]['page_url'].unique().tolist())\n",
        "\n",
        "    result = 'Long texts delta is - {}\\nCount of sites were visited - {}'.format(delta, long_text_url_visited)\n",
        "\n",
        "    save_long_text_url_list_temp(cheking_long_text_list) # 5. Save json long_text_url_list_temp\n",
        "    time.sleep(5) # time for renewing json artinvest_long_text_url_list_temp\n",
        "      \n",
        "    parsing_agg_lt(lt_file) # 11.2 Getting long texts files\n",
        "  \n",
        "  return print(result)"
      ],
      "metadata": {
        "id": "ebVyi9_sKvTs"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### collect_lines_check"
      ],
      "metadata": {
        "id": "f4kf4bSk-cEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 15. Checking collected lines\n",
        "def collect_lines_check(pages_counter_stat, news_articles_data):\n",
        "\n",
        "  pages_counter = pages_counter_stat.loc[pages_counter_stat['parsing_date']==pages_counter_stat['parsing_date'].max()][['page_url', 'page_title', 'pages_total', 'records_total']]\n",
        "  data_counter = news_articles_data.groupby(['page_title']).size().to_frame(name = 'count').reset_index()\n",
        "  global combo\n",
        "  combo = pages_counter.merge(data_counter, on='page_title', how='outer')\n",
        "  combo['delta'] = combo['records_total'] - combo['count']\n",
        "\n",
        "  global problem_archive_pages\n",
        "  problem_archive_pages = combo.loc[combo['delta']!=0]['page_url'].tolist()\n",
        "  if len(problem_archive_pages)==0:\n",
        "    print('Records delta has not found')\n",
        "  else:\n",
        "    display(combo.loc[combo['page_url'].isin(problem_archive_pages)])"
      ],
      "metadata": {
        "id": "COY8sWmI-T6_"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### date_transfomation"
      ],
      "metadata": {
        "id": "uaLL3Xn7ZbuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 14. Date transfomation\n",
        "def date_transfomation(cell):\n",
        "  try:\n",
        "    cell = pd.to_datetime(datetime.strptime(cell, '%d.%m.%Y').strftime('%Y-%m-%d')).date()\n",
        "  except ValueError:\n",
        "    cell = pd.to_datetime(cell).date()\n",
        "  return cell"
      ],
      "metadata": {
        "id": "XqDXD5wJTFSy"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sites parsing: news and articles only"
      ],
      "metadata": {
        "id": "moLctZ47_zqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for key, value in df_dict.items():\n",
        "  print(key, value[0], value[1], value[2])"
      ],
      "metadata": {
        "id": "v2JBbTg2H16s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "118bfe0c-4c50-42ab-f52b-e3ddb5cee084"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://www.theartnewspaper.ru/ - /theartnewspaper_data_new.csv /theartnewspaper_long_text.csv\n",
            "https://artinvestment.ru/ /artinvest_pages_counter_stat.csv /artinvest_news_articles_data.csv /artinvest_long_text.csv\n",
            "https://artchive.ru/ /artchive_pages_counter_stat.csv /artchive_news_articles_data.csv /artchive_long_text.csv\n",
            "https://artuzel.com/ /artusel_pages_counter_stat.csv /artuzel_news_articles_data.csv /artuzel_long_text.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !!! resurrect artinvestmant site first !!!\n",
        "for key, value in df_dict.items():\n",
        "  start_t = time.time()\n",
        "  print(key)\n",
        "  try:\n",
        "    # 11.1 Getting pages_counter_stat, pages_curr_data csv files and json long_text_url_list_temp\n",
        "    parsing_agg_sd(key, value[0], value[1], value[2])\n",
        "    #parsing_agg_sd(site, s_file, d_file, lt_file)\n",
        "    print('{} seconds have passed'.format(time.time() - start_t))\n",
        "    print('')\n",
        "  except SystemExit:\n",
        "    print('')\n",
        "    continue"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7Gqmjk6Fbwa",
        "outputId": "c53d1acd-4ea6-474f-b3aa-bc3db8ea0478"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://www.theartnewspaper.ru/\n",
            "22 articles have been collected\n",
            "in 0.02389669418334961 seconds\n",
            "22 articles have been collected\n",
            "in 0.024350404739379883 seconds\n",
            "22 articles have been collected\n",
            "in 0.024202585220336914 seconds\n",
            "22 articles have been collected\n",
            "in 0.026561737060546875 seconds\n",
            "22 articles have been collected\n",
            "in 0.02595043182373047 seconds\n",
            "22 articles have been collected\n",
            "in 0.024216175079345703 seconds\n",
            "22 articles have been collected\n",
            "in 0.023233413696289062 seconds\n",
            "22 articles have been collected\n",
            "in 0.023585796356201172 seconds\n",
            "22 articles have been collected\n",
            "in 0.026139259338378906 seconds\n",
            "22 articles have been collected\n",
            "in 0.025338172912597656 seconds\n",
            "0 text pages have been collected\n",
            "All text pages have been collected - True\n",
            "No counter block exists\n",
            "28.147531986236572 seconds have passed\n",
            "\n",
            "https://artinvestment.ru/\n",
            "HTTPError: https://artinvestment.ru/news/artnews/\n",
            "https://artchive.ru/\n",
            "10 articles have been collected\n",
            "in 0.012106180191040039 seconds\n",
            "10 articles have been collected\n",
            "in 0.01242518424987793 seconds\n",
            "10 articles have been collected\n",
            "in 0.011983394622802734 seconds\n",
            "10 articles have been collected\n",
            "in 0.01992058753967285 seconds\n",
            "10 articles have been collected\n",
            "in 0.012264013290405273 seconds\n",
            "36 articles have been collected\n",
            "in 0.020007610321044922 seconds\n",
            "36 articles have been collected\n",
            "in 0.019744873046875 seconds\n",
            "36 articles have been collected\n",
            "in 0.03805351257324219 seconds\n",
            "36 articles have been collected\n",
            "in 0.020002365112304688 seconds\n",
            "36 articles have been collected\n",
            "in 0.020438194274902344 seconds\n",
            "36 articles have been collected\n",
            "in 0.01935863494873047 seconds\n",
            "31 articles have been collected\n",
            "in 0.017674922943115234 seconds\n",
            "1 text pages have been collected\n",
            "All text pages have been collected - True\n",
            "12 new counter blocks have been collected\n",
            "All counter blocks have been collected - True\n",
            "38.38884735107422 seconds have passed\n",
            "\n",
            "https://artuzel.com/\n",
            "20 articles have been collected\n",
            "in 0.009654998779296875 seconds\n",
            "20 articles have been collected\n",
            "in 0.010492086410522461 seconds\n",
            "20 articles have been collected\n",
            "in 0.011213064193725586 seconds\n",
            "20 articles have been collected\n",
            "in 0.009206771850585938 seconds\n",
            "20 articles have been collected\n",
            "in 0.013287782669067383 seconds\n",
            "20 articles have been collected\n",
            "in 0.03586602210998535 seconds\n",
            "20 articles have been collected\n",
            "in 0.04921865463256836 seconds\n",
            "20 articles have been collected\n",
            "in 0.012937545776367188 seconds\n",
            "10 text pages have been collected\n",
            "All text pages have been collected - True\n",
            "0 new counter blocks have been collected\n",
            "All counter blocks have been collected - False\n",
            "33.29649043083191 seconds have passed\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## artinvestment.ru\n",
        "- catch artinvest's 23 empty long texts - don't see 'p' in 'block content-data article-content' - ***not actual***"
      ],
      "metadata": {
        "id": "XVkY1JNtMEyW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## theartnewspaper.ru\n",
        "- news duplicates - same news in different categories - saving just one (long_text_url) - the first one - ***is it important? - no - tags have been created***\n",
        "- there's possible to collect only ***one*** main news page"
      ],
      "metadata": {
        "id": "BnbSEEGOUGOO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## artchive.ru\n",
        "- there's possible to collect only ***two*** main news and publications pages"
      ],
      "metadata": {
        "id": "9VbpRN2f5PlI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## artuzel.com"
      ],
      "metadata": {
        "id": "_ZevwtLUsxbJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking\n",
        "check date format: datetime.strptime(cell, '%d.%m.%Y').strftime('%Y-%m-%d')\n",
        "- https://artinvestment.ru/ - 17.03.2022\n",
        "- https://www.theartnewspaper.ru/ - 18.03.2022\n",
        "- https://artchive.ru/ - 2022-03-21 23:43:28\n",
        "- http://artuzel.com/ - 17:40, 18 марта 2022"
      ],
      "metadata": {
        "id": "fwAOk1XNXTXz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "0UytDgzO2AkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Opening\n",
        "start_t = time.time()\n",
        "\n",
        "artinvest_news_articles_data = open_file_csv(artinvest_d, 'live') # 2. Open file.csv\n",
        "artinvest_long_text_df = open_file_csv(artinvest_lt, 'live') # 2. Open file.csv\n",
        "artinvest_pages_counter_stat = open_file_csv(artinvest_s, 'live') # 2. Open file.csv\n",
        "\n",
        "theartnewspaper_data = open_file_csv(theartnewspaper_d, 'live') # 2. Open file.csv\n",
        "theartnewspaper_long_text_df = open_file_csv(theartnewspaper_lt, 'live') # 2. Open file.csv\n",
        "\n",
        "artchive_news_articles_data = open_file_csv(artchive_d, 'live') # 2. Open file.csv\n",
        "artchive_long_text_df = open_file_csv(artchive_lt, 'live') # 2. Open file.csv\n",
        "artchive_pages_counter_stat = open_file_csv(artchive_s, 'live') # 2. Open file.csv\n",
        "\n",
        "artuzel_news_articles_data = open_file_csv(artuzel_d, 'live') # 2. Open file.csv\n",
        "artuzel_long_text_df = open_file_csv(artuzel_lt, 'live') # 2. Open file.csv\n",
        "artuzel_pages_counter_stat = open_file_csv(artuzel_s, 'live') # 2. Open file.csv\n",
        "\n",
        "# Dates transformation and sorting\n",
        "df_list = [artinvest_news_articles_data,\n",
        "           artinvest_pages_counter_stat,\n",
        "           theartnewspaper_data,\n",
        "           artchive_news_articles_data,\n",
        "           artchive_pages_counter_stat,\n",
        "           artuzel_news_articles_data,\n",
        "           artuzel_pages_counter_stat\n",
        "           ]\n",
        "\n",
        "for df in df_list:\n",
        "  # transformation\n",
        "  try:\n",
        "    df['parsing_date'] = df['parsing_date'].dropna().apply(lambda x: date_transfomation(x)) # 14. Date transfomation\n",
        "  except: continue\n",
        "\n",
        "# Data and long text df-s combining\n",
        "artinvest_news_articles_w_text = artinvest_news_articles_data.merge(artinvest_long_text_df, on='long_text_url', how='left')\n",
        "theartnewspaper_w_text = theartnewspaper_data.merge(theartnewspaper_long_text_df, on='long_text_url', how='left')\n",
        "artchive_news_articles_w_text = artchive_news_articles_data.merge(artchive_long_text_df, on='long_text_url', how='left')\n",
        "artuzel_news_articles_w_text = artuzel_news_articles_data.merge(artuzel_long_text_df, on='long_text_url', how='left')\n",
        "\n",
        "# topping up dict (manually yet)\n",
        "combo_df_dict = {artinvest_lt: artinvest_news_articles_w_text,\n",
        "                 theartnewspaper_lt: theartnewspaper_w_text,\n",
        "                 artchive_lt: artchive_news_articles_w_text,\n",
        "                 artuzel_lt: artuzel_news_articles_w_text\n",
        "                 }\n",
        "\n",
        "print('{} seconds have passed'.format(time.time() - start_t))"
      ],
      "metadata": {
        "id": "onof1uzkmJXg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12ebfce5-9030-4280-db23-9c3c1b43d1a5"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.68776559829712 seconds have passed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking data fullfillness"
      ],
      "metadata": {
        "id": "GijBa67E2E4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking long texts\n",
        "start_t = time.time()\n",
        "for name, df in combo_df_dict.items():\n",
        "  print(name)\n",
        "  long_text_problems_fix(name, df) # 12. Fixing long text problems\n",
        " #long_text_problems_fix(file, df)\n",
        "  print('{} seconds have passed'.format(time.time() - start_t))\n",
        "  print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aevTT62bXemL",
        "outputId": "d32adc3d-c4f3-4750-9519-db937cbb058b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/artinvest_long_text.csv\n",
            "All long texts were found\n",
            "0.05925107002258301 seconds have passed\n",
            "\n",
            "/theartnewspaper_long_text.csv\n",
            "All long texts were found\n",
            "0.06853771209716797 seconds have passed\n",
            "\n",
            "/artchive_long_text.csv\n",
            "All long texts were found\n",
            "0.08987855911254883 seconds have passed\n",
            "\n",
            "/artuzel_long_text.csv\n",
            "All long texts were found\n",
            "0.10982513427734375 seconds have passed\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### artinvestment.ru"
      ],
      "metadata": {
        "id": "Gn1FIyrPLrgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking ARTINVEST collected lines\n",
        "collect_lines_check(df_list[1], df_list[0]) # 15. Checking collected lines\n",
        "#collect_lines_check(pages_counter_stat, news_articles_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "Se2vOJye82jQ",
        "outputId": "379efc56-2b69-423c-8658-ec4164428f7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  page_url             page_title  pages_total  records_total  count  delta\n",
              "9      NaN  Рассказы о художниках          NaN            NaN     56    NaN"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-67814882-59ea-409e-9c19-d9c53808f8fe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>page_url</th>\n",
              "      <th>page_title</th>\n",
              "      <th>pages_total</th>\n",
              "      <th>records_total</th>\n",
              "      <th>count</th>\n",
              "      <th>delta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Рассказы о художниках</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>56</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67814882-59ea-409e-9c19-d9c53808f8fe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-67814882-59ea-409e-9c19-d9c53808f8fe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-67814882-59ea-409e-9c19-d9c53808f8fe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stopped collecting for now:\n",
        "- Обзоры событий в мире искусства\n",
        "- Рассказы о художниках"
      ],
      "metadata": {
        "id": "vObZzbYvAhxo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### artchive.ru"
      ],
      "metadata": {
        "id": "KYgqWnYlLxzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking ARTCHIVE collected lines\n",
        "collect_lines_check(df_list[4], df_list[3]) # 15. Checking collected lines\n",
        "#collect_lines_check(pages_counter_stat, news_articles_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "R6NkCGOz9u0V",
        "outputId": "0abc222d-2f5d-4983-f55c-2fb6e4d8fb8f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                             page_url             page_title  \\\n",
              "0                            https://artchive.ru/news            Все новости   \n",
              "1              https://artchive.ru/news/rubric:events     События и выставки   \n",
              "3   https://artchive.ru/news/rubric:sales_and_auct...        Продажи и торги   \n",
              "4              https://artchive.ru/news/rubric:modern  Современное искусство   \n",
              "5                    https://artchive.ru/publications             Все статьи   \n",
              "7       https://artchive.ru/publications/for_beginers               Новичкам   \n",
              "8            https://artchive.ru/publications/experts              Экспертам   \n",
              "9         https://artchive.ru/publications/collectors         Коллекционерам   \n",
              "10  https://artchive.ru/publications/aritist_biogr...             Персоналии   \n",
              "11       https://artchive.ru/publications/for_artists             Художникам   \n",
              "12                                                NaN           Знаете ли вы   \n",
              "\n",
              "    pages_total  records_total  count   delta  \n",
              "0          85.0         3051.0    371  2680.0  \n",
              "1          52.0         1864.0    366  1498.0  \n",
              "3          11.0          388.0    329    59.0  \n",
              "4          19.0          670.0    138   532.0  \n",
              "5          28.0          994.0     35   959.0  \n",
              "7          19.0          670.0    477   193.0  \n",
              "8           9.0          302.0     12   290.0  \n",
              "9           5.0          175.0    136    39.0  \n",
              "10         14.0          493.0    222   271.0  \n",
              "11          NaN            NaN     18     NaN  \n",
              "12          NaN            NaN      1     NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8f0946ff-2a5a-458c-82e6-dfe5738c2322\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>page_url</th>\n",
              "      <th>page_title</th>\n",
              "      <th>pages_total</th>\n",
              "      <th>records_total</th>\n",
              "      <th>count</th>\n",
              "      <th>delta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://artchive.ru/news</td>\n",
              "      <td>Все новости</td>\n",
              "      <td>85.0</td>\n",
              "      <td>3051.0</td>\n",
              "      <td>371</td>\n",
              "      <td>2680.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://artchive.ru/news/rubric:events</td>\n",
              "      <td>События и выставки</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1864.0</td>\n",
              "      <td>366</td>\n",
              "      <td>1498.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://artchive.ru/news/rubric:sales_and_auct...</td>\n",
              "      <td>Продажи и торги</td>\n",
              "      <td>11.0</td>\n",
              "      <td>388.0</td>\n",
              "      <td>329</td>\n",
              "      <td>59.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://artchive.ru/news/rubric:modern</td>\n",
              "      <td>Современное искусство</td>\n",
              "      <td>19.0</td>\n",
              "      <td>670.0</td>\n",
              "      <td>138</td>\n",
              "      <td>532.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>https://artchive.ru/publications</td>\n",
              "      <td>Все статьи</td>\n",
              "      <td>28.0</td>\n",
              "      <td>994.0</td>\n",
              "      <td>35</td>\n",
              "      <td>959.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>https://artchive.ru/publications/for_beginers</td>\n",
              "      <td>Новичкам</td>\n",
              "      <td>19.0</td>\n",
              "      <td>670.0</td>\n",
              "      <td>477</td>\n",
              "      <td>193.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>https://artchive.ru/publications/experts</td>\n",
              "      <td>Экспертам</td>\n",
              "      <td>9.0</td>\n",
              "      <td>302.0</td>\n",
              "      <td>12</td>\n",
              "      <td>290.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>https://artchive.ru/publications/collectors</td>\n",
              "      <td>Коллекционерам</td>\n",
              "      <td>5.0</td>\n",
              "      <td>175.0</td>\n",
              "      <td>136</td>\n",
              "      <td>39.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>https://artchive.ru/publications/aritist_biogr...</td>\n",
              "      <td>Персоналии</td>\n",
              "      <td>14.0</td>\n",
              "      <td>493.0</td>\n",
              "      <td>222</td>\n",
              "      <td>271.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>https://artchive.ru/publications/for_artists</td>\n",
              "      <td>Художникам</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Знаете ли вы</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f0946ff-2a5a-458c-82e6-dfe5738c2322')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8f0946ff-2a5a-458c-82e6-dfe5738c2322 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8f0946ff-2a5a-458c-82e6-dfe5738c2322');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "artchive_news_articles_data.loc[artchive_news_articles_data['page_title']=='Знаете ли вы'][['page_url', 'title']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "CidGyw4pVwvg",
        "outputId": "df2fc51f-f030-486f-f3b4-43d00e1f7072"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         page_url    title\n",
              "224  https://artchive.ru/publications/for_artists  Мозаика"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-88caf4f7-cbe0-4179-a20a-194df19cb494\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>page_url</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>https://artchive.ru/publications/for_artists</td>\n",
              "      <td>Мозаика</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88caf4f7-cbe0-4179-a20a-194df19cb494')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-88caf4f7-cbe0-4179-a20a-194df19cb494 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-88caf4f7-cbe0-4179-a20a-194df19cb494');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Follow the tag 'Знаете ли вы'\n",
        "- 'Художникам' - 1 page list"
      ],
      "metadata": {
        "id": "XNJpaM7NWtFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combo['section'] = combo['page_url'].dropna().apply(lambda x: x.split('/')[3])\n",
        "news_c = combo.loc[combo['page_title']=='Все новости']['records_total']\n",
        "news_sect_c = combo.loc[(combo['section']=='news')&(combo['page_title']!='Все новости')]['records_total'].sum()\n",
        "print(news_c==news_sect_c)\n",
        "print('Delta is {}'.format(news_c-news_sect_c))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7NdfswDQpnn",
        "outputId": "16bd1031-ad20-4604-b701-8f38a85c53eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    False\n",
            "Name: records_total, dtype: bool\n",
            "Delta is 0   -1716.0\n",
            "Name: records_total, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "public_c = combo.loc[combo['page_title']=='Все статьи']['records_total']\n",
        "public_sect_c = combo.loc[(combo['section']=='publications')&(combo['page_title']!='Все статьи')]['records_total'].sum()\n",
        "print(public_c==public_sect_c)\n",
        "print('Delta is {}'.format(public_c-public_sect_c))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWf-4wWQQqT5",
        "outputId": "3f6bf5d6-6b05-45c6-ece0-4b206cb2a0b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5    False\n",
            "Name: records_total, dtype: bool\n",
            "Delta is 5   -739.0\n",
            "Name: records_total, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Actually, it's not possible to check the fullfillness because one news can refer to several sections and I collect them just once. So, if the difference is negative, then ok."
      ],
      "metadata": {
        "id": "wOKYfCogUPLY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### artuzel.com"
      ],
      "metadata": {
        "id": "92YZGQf7L5E0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking ARTUZEL collected lines\n",
        "collect_lines_check(df_list[6], df_list[5]) # 15. Checking collected lines\n",
        "#collect_lines_check(pages_counter_stat, news_articles_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "np1MvpE82KLu",
        "outputId": "898fbb6f-7f21-4447-d35d-a38f13c49ffc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                          page_url            page_title  pages_total  \\\n",
              "0          http://artuzel.com/news               Новости         75.0   \n",
              "1   http://artuzel.com/exhibitions              Выставки         64.0   \n",
              "2    http://artuzel.com/ru/regions            Не столицы          NaN   \n",
              "3  http://artuzel.com/competitions     Конкурсы и гранты         33.0   \n",
              "4      http://artuzel.com/lectures                Лекции         35.0   \n",
              "5     http://artuzel.com/interview  Интервью и дискуссии          NaN   \n",
              "6      http://artuzel.com/articles                Статьи          NaN   \n",
              "7     http://artuzel.com/festivals             Фестивали          NaN   \n",
              "\n",
              "   records_total  count  delta  \n",
              "0            NaN   1495    NaN  \n",
              "1            NaN   1274    NaN  \n",
              "2            NaN     47    NaN  \n",
              "3            NaN    648    NaN  \n",
              "4            NaN    699    NaN  \n",
              "5            NaN    385    NaN  \n",
              "6            NaN    527    NaN  \n",
              "7            NaN     26    NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2c256d7b-b670-4f35-855b-4f07ef06563d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>page_url</th>\n",
              "      <th>page_title</th>\n",
              "      <th>pages_total</th>\n",
              "      <th>records_total</th>\n",
              "      <th>count</th>\n",
              "      <th>delta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>http://artuzel.com/news</td>\n",
              "      <td>Новости</td>\n",
              "      <td>75.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1495</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>http://artuzel.com/exhibitions</td>\n",
              "      <td>Выставки</td>\n",
              "      <td>64.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1274</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>http://artuzel.com/ru/regions</td>\n",
              "      <td>Не столицы</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>47</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>http://artuzel.com/competitions</td>\n",
              "      <td>Конкурсы и гранты</td>\n",
              "      <td>33.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>648</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>http://artuzel.com/lectures</td>\n",
              "      <td>Лекции</td>\n",
              "      <td>35.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>699</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>http://artuzel.com/interview</td>\n",
              "      <td>Интервью и дискуссии</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>385</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>http://artuzel.com/articles</td>\n",
              "      <td>Статьи</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>527</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>http://artuzel.com/festivals</td>\n",
              "      <td>Фестивали</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>26</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c256d7b-b670-4f35-855b-4f07ef06563d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2c256d7b-b670-4f35-855b-4f07ef06563d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2c256d7b-b670-4f35-855b-4f07ef06563d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combo['records_total'] = combo['records_total'].fillna(20 * combo['pages_total'])\n",
        "combo['delta'] = combo['records_total'] - combo['count']\n",
        "combo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "dgHGJa2ph9BG",
        "outputId": "543ff7a9-8582-4699-f54d-5035cddd5854"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          page_url            page_title  pages_total  \\\n",
              "0          http://artuzel.com/news               Новости         75.0   \n",
              "1   http://artuzel.com/exhibitions              Выставки         64.0   \n",
              "2    http://artuzel.com/ru/regions            Не столицы          NaN   \n",
              "3  http://artuzel.com/competitions     Конкурсы и гранты         33.0   \n",
              "4      http://artuzel.com/lectures                Лекции         35.0   \n",
              "5     http://artuzel.com/interview  Интервью и дискуссии          NaN   \n",
              "6      http://artuzel.com/articles                Статьи          NaN   \n",
              "7     http://artuzel.com/festivals             Фестивали          NaN   \n",
              "\n",
              "   records_total  count  delta  \n",
              "0         1500.0   1495    5.0  \n",
              "1         1280.0   1274    6.0  \n",
              "2            NaN     47    NaN  \n",
              "3          660.0    648   12.0  \n",
              "4          700.0    699    1.0  \n",
              "5            NaN    385    NaN  \n",
              "6            NaN    527    NaN  \n",
              "7            NaN     26    NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b133d0a9-35bc-432a-9b1f-e3b2fe7b32f2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>page_url</th>\n",
              "      <th>page_title</th>\n",
              "      <th>pages_total</th>\n",
              "      <th>records_total</th>\n",
              "      <th>count</th>\n",
              "      <th>delta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>http://artuzel.com/news</td>\n",
              "      <td>Новости</td>\n",
              "      <td>75.0</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>1495</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>http://artuzel.com/exhibitions</td>\n",
              "      <td>Выставки</td>\n",
              "      <td>64.0</td>\n",
              "      <td>1280.0</td>\n",
              "      <td>1274</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>http://artuzel.com/ru/regions</td>\n",
              "      <td>Не столицы</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>47</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>http://artuzel.com/competitions</td>\n",
              "      <td>Конкурсы и гранты</td>\n",
              "      <td>33.0</td>\n",
              "      <td>660.0</td>\n",
              "      <td>648</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>http://artuzel.com/lectures</td>\n",
              "      <td>Лекции</td>\n",
              "      <td>35.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>699</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>http://artuzel.com/interview</td>\n",
              "      <td>Интервью и дискуссии</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>385</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>http://artuzel.com/articles</td>\n",
              "      <td>Статьи</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>527</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>http://artuzel.com/festivals</td>\n",
              "      <td>Фестивали</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>26</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b133d0a9-35bc-432a-9b1f-e3b2fe7b32f2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b133d0a9-35bc-432a-9b1f-e3b2fe7b32f2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b133d0a9-35bc-432a-9b1f-e3b2fe7b32f2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Very few sections have pages (20 articles on each), the others contain all articles accumulatively. It isn't possible to check the data fullfillness. Records total is calculated. So if delta is less than 20, then ok."
      ],
      "metadata": {
        "id": "SX1t7r9Qnzu7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parsing ARCHIVE\n",
        "\n",
        "!!!\n",
        "\n",
        "9.4 Parsing artuzel current news_articles_data - get_artuz_pages_curr_data - requires changings\n",
        "\n",
        "!!!"
      ],
      "metadata": {
        "id": "z8UNbBFFvrJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 13. Parsing news_articles_data ARCHIVE\n",
        "start_t = time.time()\n",
        "\n",
        "confirmation = input('Confirm the archive parsing (y/n)')\n",
        "if confirmation == 'y':\n",
        "  print('Parsing is started')\n",
        "  parsing_agg_a_n_archive(artuzel_s, artuzel_d, artuzel_lt, problem_archive_pages[7]) # 11.3 Parsing news_articles_data ARCHIVE\n",
        " #get_news_articles_archive(s_file, d_file, lt_file, p_url)\n",
        "else:\n",
        "  print('Nothing has happened')\n",
        "\n",
        "print('{} seconds have passed'.format(time.time() - start_t))"
      ],
      "metadata": {
        "id": "5VMbZsklahET",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91578754-8fca-4ac1-e7a4-bba39cca8538"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confirm the archive parsing (y/n)y\n",
            "Parsing is started\n",
            "26 articles have been collected\n",
            "in 0.020172119140625 seconds\n",
            "6 text pages have been collected\n",
            "All text pages have been collected - True\n",
            "19.785218477249146 seconds have passed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Backup saving"
      ],
      "metadata": {
        "id": "m8rV6iASHojd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_df_file(artinvest_news_articles_data, artinvest_d.replace('.csv', '') + '_' + str(datetime.now().date()) + '.csv', 'backup') # 3. Save df to csv file\n",
        "save_df_file(artinvest_long_text_df, artinvest_lt.replace('.csv', '') + '_' + str(datetime.now().date()) + '.csv', 'backup') # 3. Save df to csv file\n",
        "\n",
        "save_df_file(theartnewspaper_data, theartnewspaper_d.replace('.csv', '') + '_' + str(datetime.now().date()) + '.csv', 'backup') # 3. Save df to csv file\n",
        "save_df_file(theartnewspaper_long_text_df, theartnewspaper_lt.replace('.csv', '') + '_' + str(datetime.now().date()) + '.csv', 'backup') # 3. Save df to csv file\n",
        "\n",
        "save_df_file(artchive_news_articles_data, artchive_d.replace('.csv', '') + '_' + str(datetime.now().date()) + '.csv', 'backup') # 3. Save df to csv file\n",
        "save_df_file(artchive_long_text_df, artchive_lt.replace('.csv', '') + '_' + str(datetime.now().date()) + '.csv', 'backup') # 3. Save df to csv file\n",
        "\n",
        "save_df_file(artuzel_news_articles_data, artuzel_d.replace('.csv', '') + '_' + str(datetime.now().date()) + '.csv', 'backup') # 3. Save df to csv file\n",
        "save_df_file(artuzel_long_text_df, artuzel_lt.replace('.csv', '') + '_' + str(datetime.now().date()) + '.csv', 'backup') # 3. Save df to csv file\n",
        "\n",
        "#save_df_file(df, file, folder)"
      ],
      "metadata": {
        "id": "bULgNkadEl_2"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## df info"
      ],
      "metadata": {
        "id": "2TB9_lIw1iSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# new info\n",
        "for key, value in df_dict.items():\n",
        "  for v in value:\n",
        "    print(v)\n",
        "    print('')\n",
        "    try:\n",
        "      df = open_file_csv(v, 'live') # 2. Open file.csv\n",
        "      df.info()\n",
        "    except:\n",
        "      continue\n",
        "    finally:\n",
        "      print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b2f3E56IMS2",
        "outputId": "6fd4bc0d-4c56-4baa-b57b-f94bceb1d2a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "\n",
            "\n",
            "/theartnewspaper_data_new.csv\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1013 entries, 0 to 1012\n",
            "Data columns (total 10 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   date               1013 non-null   object \n",
            " 1   link               1013 non-null   object \n",
            " 2   title              1013 non-null   object \n",
            " 3   short_text         1013 non-null   object \n",
            " 4   page_url           1013 non-null   object \n",
            " 5   page_title         1013 non-null   object \n",
            " 6   long_text_url      1013 non-null   object \n",
            " 7   parsing_date       1013 non-null   object \n",
            " 8   parsing_time       1013 non-null   object \n",
            " 9   parsing_sec_speed  1013 non-null   float64\n",
            "dtypes: float64(1), object(9)\n",
            "memory usage: 79.3+ KB\n",
            "\n",
            "/theartnewspaper_long_text.csv\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1013 entries, 0 to 1012\n",
            "Data columns (total 7 columns):\n",
            " #   Column               Non-Null Count  Dtype \n",
            "---  ------               --------------  ----- \n",
            " 0   long_text_url        1013 non-null   object\n",
            " 1   long_text            1013 non-null   object\n",
            " 2   structure            1013 non-null   object\n",
            " 3   images               1013 non-null   object\n",
            " 4   sourses              1013 non-null   object\n",
            " 5   tags                 1013 non-null   object\n",
            " 6   parsing_sec_speed_2  1013 non-null   object\n",
            "dtypes: object(7)\n",
            "memory usage: 55.5+ KB\n",
            "\n",
            "/artinvest_pages_counter_stat.csv\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 165 entries, 0 to 164\n",
            "Data columns (total 10 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   page_url           165 non-null    object \n",
            " 1   page_title         165 non-null    object \n",
            " 2   records_total      165 non-null    int64  \n",
            " 3   pages_total        165 non-null    int64  \n",
            " 4   records_max        165 non-null    int64  \n",
            " 5   records_value      165 non-null    int64  \n",
            " 6   first_page_url     165 non-null    object \n",
            " 7   parsing_date       165 non-null    object \n",
            " 8   parsing_time       165 non-null    object \n",
            " 9   parsing_sec_speed  165 non-null    float64\n",
            "dtypes: float64(1), int64(4), object(5)\n",
            "memory usage: 13.0+ KB\n",
            "\n",
            "/artinvest_news_articles_data.csv\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 13167 entries, 0 to 13166\n",
            "Data columns (total 10 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   date               13167 non-null  object \n",
            " 1   link               13167 non-null  object \n",
            " 2   title              13167 non-null  object \n",
            " 3   short_text         13167 non-null  object \n",
            " 4   page_url           13167 non-null  object \n",
            " 5   page_title         13167 non-null  object \n",
            " 6   long_text_url      13167 non-null  object \n",
            " 7   parsing_date       13167 non-null  object \n",
            " 8   parsing_time       13167 non-null  object \n",
            " 9   parsing_sec_speed  13167 non-null  float64\n",
            "dtypes: float64(1), object(9)\n",
            "memory usage: 1.0+ MB\n",
            "\n",
            "/artinvest_long_text.csv\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 13167 entries, 0 to 13166\n",
            "Data columns (total 7 columns):\n",
            " #   Column               Non-Null Count  Dtype \n",
            "---  ------               --------------  ----- \n",
            " 0   long_text_url        13167 non-null  object\n",
            " 1   long_text            13167 non-null  object\n",
            " 2   structure            13167 non-null  object\n",
            " 3   images               13167 non-null  object\n",
            " 4   sourses              13167 non-null  object\n",
            " 5   tags                 13167 non-null  object\n",
            " 6   parsing_sec_speed_2  13167 non-null  object\n",
            "dtypes: object(7)\n",
            "memory usage: 720.2+ KB\n",
            "\n",
            "/artchive_pages_counter_stat.csv\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 25 entries, 0 to 24\n",
            "Data columns (total 10 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   page_url           25 non-null     object \n",
            " 1   page_title         25 non-null     object \n",
            " 2   records_total      24 non-null     float64\n",
            " 3   pages_total        25 non-null     int64  \n",
            " 4   records_max        25 non-null     int64  \n",
            " 5   records_value      13 non-null     object \n",
            " 6   first_page_url     25 non-null     object \n",
            " 7   parsing_date       25 non-null     object \n",
            " 8   parsing_time       25 non-null     object \n",
            " 9   parsing_sec_speed  25 non-null     float64\n",
            "dtypes: float64(2), int64(2), object(6)\n",
            "memory usage: 2.1+ KB\n",
            "\n",
            "/artchive_news_articles_data.csv\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4037 entries, 0 to 4036\n",
            "Data columns (total 10 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   date               4037 non-null   object \n",
            " 1   link               4037 non-null   object \n",
            " 2   title              4037 non-null   object \n",
            " 3   short_text         4037 non-null   object \n",
            " 4   page_url           4037 non-null   object \n",
            " 5   page_title         4037 non-null   object \n",
            " 6   long_text_url      4037 non-null   object \n",
            " 7   parsing_date       4037 non-null   object \n",
            " 8   parsing_time       4037 non-null   object \n",
            " 9   parsing_sec_speed  4037 non-null   float64\n",
            "dtypes: float64(1), object(9)\n",
            "memory usage: 315.5+ KB\n",
            "\n",
            "/artchive_long_text.csv\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4037 entries, 0 to 4036\n",
            "Data columns (total 7 columns):\n",
            " #   Column               Non-Null Count  Dtype \n",
            "---  ------               --------------  ----- \n",
            " 0   long_text_url        4037 non-null   object\n",
            " 1   long_text            4037 non-null   object\n",
            " 2   structure            4037 non-null   object\n",
            " 3   images               4037 non-null   object\n",
            " 4   sourses              4037 non-null   object\n",
            " 5   tags                 4037 non-null   object\n",
            " 6   parsing_sec_speed_2  4037 non-null   object\n",
            "dtypes: object(7)\n",
            "memory usage: 220.9+ KB\n",
            "\n",
            "/artusel_pages_counter_stat.csv\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 16 entries, 0 to 15\n",
            "Data columns (total 10 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   page_url           16 non-null     object \n",
            " 1   page_title         16 non-null     object \n",
            " 2   records_total      0 non-null      float64\n",
            " 3   pages_total        8 non-null      float64\n",
            " 4   records_max        0 non-null      float64\n",
            " 5   records_value      0 non-null      float64\n",
            " 6   first_page_url     16 non-null     object \n",
            " 7   parsing_date       16 non-null     object \n",
            " 8   parsing_time       16 non-null     object \n",
            " 9   parsing_sec_speed  16 non-null     float64\n",
            "dtypes: float64(5), object(5)\n",
            "memory usage: 1.4+ KB\n",
            "\n",
            "/artuzel_news_articles_data.csv\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5089 entries, 0 to 5088\n",
            "Data columns (total 10 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   date               5089 non-null   object \n",
            " 1   link               5089 non-null   object \n",
            " 2   title              5089 non-null   object \n",
            " 3   short_text         5089 non-null   object \n",
            " 4   page_url           5089 non-null   object \n",
            " 5   page_title         5089 non-null   object \n",
            " 6   long_text_url      5089 non-null   object \n",
            " 7   parsing_date       5089 non-null   object \n",
            " 8   parsing_time       5089 non-null   object \n",
            " 9   parsing_sec_speed  5089 non-null   float64\n",
            "dtypes: float64(1), object(9)\n",
            "memory usage: 397.7+ KB\n",
            "\n",
            "/artuzel_long_text.csv\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5089 entries, 0 to 5088\n",
            "Data columns (total 7 columns):\n",
            " #   Column               Non-Null Count  Dtype \n",
            "---  ------               --------------  ----- \n",
            " 0   long_text_url        5089 non-null   object\n",
            " 1   long_text            5089 non-null   object\n",
            " 2   structure            5089 non-null   object\n",
            " 3   images               5089 non-null   object\n",
            " 4   sourses              5089 non-null   object\n",
            " 5   tags                 5089 non-null   object\n",
            " 6   parsing_sec_speed_2  5089 non-null   object\n",
            "dtypes: object(7)\n",
            "memory usage: 278.4+ KB\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# previouse info\n",
        "for key, value in df_dict.items():\n",
        "  for v in value:\n",
        "    print(v)\n",
        "    print('')\n",
        "    try:\n",
        "      df = open_file_csv(v, 'live') # 2. Open file.csv\n",
        "      df.info()\n",
        "    except:\n",
        "      continue\n",
        "    finally:\n",
        "      print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wcv535V_I6MI",
        "outputId": "61a6a740-b6ac-4cca-ced2-75883d80db55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "\n",
            "\n",
            "/theartnewspaper_data_new.csv\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 974 entries, 0 to 973\n",
            "Data columns (total 10 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   date               974 non-null    object \n",
            " 1   link               974 non-null    object \n",
            " 2   title              974 non-null    object \n",
            " 3   short_text         974 non-null    object \n",
            " 4   page_url           974 non-null    object \n",
            " 5   page_title         974 non-null    object \n",
            " 6   long_text_url      974 non-null    object \n",
            " 7   parsing_date       974 non-null    object \n",
            " 8   parsing_time       974 non-null    object \n",
            " 9   parsing_sec_speed  974 non-null    float64\n",
            "dtypes: float64(1), object(9)\n",
            "memory usage: 76.2+ KB\n",
            "\n",
            "/theartnewspaper_long_text.csv\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 974 entries, 0 to 973\n",
            "Data columns (total 7 columns):\n",
            " #   Column               Non-Null Count  Dtype \n",
            "---  ------               --------------  ----- \n",
            " 0   long_text_url        974 non-null    object\n",
            " 1   long_text            974 non-null    object\n",
            " 2   structure            974 non-null    object\n",
            " 3   images               974 non-null    object\n",
            " 4   sourses              974 non-null    object\n",
            " 5   tags                 974 non-null    object\n",
            " 6   parsing_sec_speed_2  974 non-null    object\n",
            "dtypes: object(7)\n",
            "memory usage: 53.4+ KB\n",
            "\n",
            "/artinvest_pages_counter_stat.csv\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 151 entries, 0 to 150\n",
            "Data columns (total 10 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   page_url           151 non-null    object \n",
            " 1   page_title         151 non-null    object \n",
            " 2   records_total      151 non-null    int64  \n",
            " 3   pages_total        151 non-null    int64  \n",
            " 4   records_max        151 non-null    int64  \n",
            " 5   records_value      151 non-null    int64  \n",
            " 6   first_page_url     151 non-null    object \n",
            " 7   parsing_date       151 non-null    object \n",
            " 8   parsing_time       151 non-null    object \n",
            " 9   parsing_sec_speed  151 non-null    float64\n",
            "dtypes: float64(1), int64(4), object(5)\n",
            "memory usage: 11.9+ KB\n",
            "\n",
            "/artinvest_news_articles_data.csv\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 13045 entries, 0 to 13044\n",
            "Data columns (total 10 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   date               13045 non-null  object \n",
            " 1   link               13045 non-null  object \n",
            " 2   title              13045 non-null  object \n",
            " 3   short_text         13045 non-null  object \n",
            " 4   page_url           13045 non-null  object \n",
            " 5   page_title         13045 non-null  object \n",
            " 6   long_text_url      13045 non-null  object \n",
            " 7   parsing_date       13045 non-null  object \n",
            " 8   parsing_time       13045 non-null  object \n",
            " 9   parsing_sec_speed  13045 non-null  float64\n",
            "dtypes: float64(1), object(9)\n",
            "memory usage: 1019.3+ KB\n",
            "\n",
            "/artinvest_long_text.csv\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 13045 entries, 0 to 13044\n",
            "Data columns (total 7 columns):\n",
            " #   Column               Non-Null Count  Dtype \n",
            "---  ------               --------------  ----- \n",
            " 0   long_text_url        13045 non-null  object\n",
            " 1   long_text            13045 non-null  object\n",
            " 2   structure            13045 non-null  object\n",
            " 3   images               13045 non-null  object\n",
            " 4   sourses              13045 non-null  object\n",
            " 5   tags                 13045 non-null  object\n",
            " 6   parsing_sec_speed_2  13045 non-null  object\n",
            "dtypes: object(7)\n",
            "memory usage: 713.5+ KB\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YVFiJGK3qzMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DlPCKfmZFjY0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}